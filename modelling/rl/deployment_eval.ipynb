{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a1e2836",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82a46cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../external/tslib')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b799b0",
   "metadata": {},
   "source": [
    "### Simulator implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75dd97a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Task:\n",
    "    id: str\n",
    "    request_time: int\n",
    "    duration: int\n",
    "    start_time: Optional[int] = None\n",
    "    end_time: Optional[int] = None\n",
    "    assigned_worker: Optional[str] = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Task({self.id}|{self.duration}ms|{self.assigned_worker}|{self.request_time}-{self.start_time}-{self.end_time})\"\n",
    "\n",
    "@dataclass\n",
    "class MetricsDataPoint:\n",
    "    time: int = 0\n",
    "    expected_workers: int = 0\n",
    "    active_workers: int = 0\n",
    "    total_workers: int = 0\n",
    "    num_new_tasks: int = 0\n",
    "    num_ongoing_tasks: int = 0\n",
    "    num_queued_tasks: int = 0\n",
    "    num_completed_tasks: int = 0\n",
    "    avg_delay: float = 0.0\n",
    "    avg_duration: float = 0.0\n",
    "    reward: float = 0.0\n",
    "    completed_tasks: List['Task'] = field(default_factory=list)\n",
    "    \n",
    "def generate_reward_function(metrics_window: float, value_per_task: float = 0.001, cost_per_worker_hour: float = 1, delay_threshold: int = 8000) -> float:\n",
    "    # Example reward function: negative of average delay\n",
    "    return lambda metrics: (\n",
    "        sum([0 if (task.end_time - task.request_time) > delay_threshold else value_per_task for task in metrics.completed_tasks]) -\n",
    "        cost_per_worker_hour * (metrics.total_workers * metrics_window / 3600000 )\n",
    "    )\n",
    "\n",
    "class Worker:\n",
    "    def __init__(self, init_time: int = 0):\n",
    "        self.id = \"worker-\" + str(random.randint(0, 10000))\n",
    "        self.available_at = init_time\n",
    "        self.active = False  # ÊòØÂê¶Â∑≤ÁªèÂàùÂßãÂåñÂÆåÊàê\n",
    "\n",
    "    def assign_task(self, task: Task, current_time: int):\n",
    "        if current_time < self.available_at:\n",
    "            task.start_time = self.available_at\n",
    "            self.available_at += task.duration\n",
    "        else:\n",
    "            task.start_time = current_time\n",
    "            self.available_at = current_time + task.duration\n",
    "        task.end_time = self.available_at\n",
    "        task.assigned_worker = self.id\n",
    "    \n",
    "    def is_available(self, current_time: int) -> bool:\n",
    "        return self.available_at <= current_time and self.active\n",
    "    \n",
    "\n",
    "\n",
    "class Simulator:\n",
    "    def __init__(self, tasks: List[Task], init_workers: int = 1, worker_init_time_min : int = 12000, worker_init_time_max : int = 12000, metrics_window: int = 10000, reward_function=None):\n",
    "        self.tasks = sorted(tasks, key=lambda t: t.request_time)\n",
    "        self.time = 0  \n",
    "        self.metrics_window = metrics_window\n",
    "        self.worker_init_time_min = worker_init_time_min\n",
    "        self.worker_init_time_max = worker_init_time_max\n",
    "        self.expected_workers = init_workers\n",
    "        self.workers = [Worker(self.__get_worker_init_time()) for i in range(init_workers)]\n",
    "        self.terminating_workers: List[Task] = []\n",
    "        self.in_progress: List[Task] = []\n",
    "        self.queued: List[Task] = []\n",
    "        self.completed_tasks: List[Task] = []\n",
    "\n",
    "        self.new_tasks = 0\n",
    "        self.metrics: List[MetricsDataPoint] = []\n",
    "        self.reward_function = reward_function\n",
    "\n",
    "    def tick(self): # tick 1s\n",
    "        self.time += 1000\n",
    "        # check completed tasks\n",
    "        for task in self.in_progress:\n",
    "            if task.end_time <= self.time:\n",
    "                self.completed_tasks.append(task)\n",
    "                self.in_progress.remove(task)\n",
    "        # check initialized workers\n",
    "        for w in self.workers:\n",
    "            if not w.active and self.time >= w.available_at:\n",
    "                w.active = True\n",
    "        # check terminating workers\n",
    "        self.terminating_workers = [w for w in self.terminating_workers if w.available_at >= self.time]\n",
    "        \n",
    "        worker = self.__get_available_worker(self.time)\n",
    "        # pop queued tasks\n",
    "        while worker and self.queued:\n",
    "            task = self.queued.pop(0)\n",
    "            worker.assign_task(task, task.request_time)\n",
    "            self.in_progress.append(task)\n",
    "            worker = self.__get_available_worker(self.time)\n",
    "        # pop new tasks\n",
    "        while self.tasks and self.tasks[0].request_time < self.time:\n",
    "            task = self.tasks.pop(0)\n",
    "            self.new_tasks += 1\n",
    "            if worker:\n",
    "                worker.assign_task(task, self.time)\n",
    "                self.in_progress.append(task)\n",
    "                worker = self.__get_available_worker(self.time)\n",
    "            else:\n",
    "                self.queued.append(task)\n",
    "        # report metrics\n",
    "        if self.time % self.metrics_window == 0:\n",
    "            self.report_metrics()\n",
    "\n",
    "    def scale(self, expected_workers: int):\n",
    "        if expected_workers > self.expected_workers:\n",
    "            for _ in range(expected_workers - self.expected_workers):\n",
    "                worker = Worker(self.time + self.__get_worker_init_time())\n",
    "                self.workers.append(worker)\n",
    "        elif expected_workers < self.expected_workers:\n",
    "            for _ in range(self.expected_workers - expected_workers):\n",
    "                for w in self.workers:\n",
    "                    if not w.active:\n",
    "                        worker = w\n",
    "                        self.workers.remove(worker)\n",
    "                        break\n",
    "                else:\n",
    "                    worker = self.workers.pop()\n",
    "                self.terminating_workers.append(worker)\n",
    "        self.expected_workers = expected_workers\n",
    "\n",
    "    def report_metrics(self):\n",
    "        if self.completed_tasks:\n",
    "            avg_delay = int(np.mean([t.end_time - t.request_time for t in self.completed_tasks]))\n",
    "            avg_duration = int(np.mean([t.end_time - t.start_time for t in self.completed_tasks]))\n",
    "        else:\n",
    "            avg_delay = 0\n",
    "            avg_duration = 0\n",
    "        dataPoint = MetricsDataPoint(\n",
    "            time=self.time,\n",
    "            expected_workers=self.expected_workers,\n",
    "            active_workers=len([w for w in self.workers if w.active]),\n",
    "            total_workers=len(self.workers) + len(self.terminating_workers),\n",
    "            num_new_tasks=self.new_tasks,\n",
    "            num_ongoing_tasks=len(self.in_progress) + len(self.queued),\n",
    "            num_queued_tasks=len(self.queued),\n",
    "            num_completed_tasks=len(self.completed_tasks),\n",
    "            avg_delay=avg_delay,\n",
    "            avg_duration=avg_duration,\n",
    "            completed_tasks=self.completed_tasks.copy(),\n",
    "            reward=0,  # Placeholder for reward, to be calculated later\n",
    "        )\n",
    "        if self.reward_function:\n",
    "            dataPoint.reward = self.reward_function(dataPoint)\n",
    "        self.metrics.append(dataPoint)\n",
    "        self.completed_tasks.clear()\n",
    "        self.new_tasks = 0\n",
    "        \n",
    "    def plot_metrics(self, tmp_output_dir: str = None):\n",
    "        metric_keys = [\n",
    "            'expected_workers',\n",
    "            'active_workers',\n",
    "            'total_workers',\n",
    "            'num_new_tasks',\n",
    "            'num_ongoing_tasks',\n",
    "            'num_queued_tasks',\n",
    "            'num_completed_tasks',\n",
    "            'avg_delay',\n",
    "            'avg_duration',\n",
    "            'reward'\n",
    "        ]\n",
    "\n",
    "        data = {key: [] for key in metric_keys}\n",
    "        time_s = [int(m.time / 1000) for m in self.metrics]\n",
    "\n",
    "        for metrics in self.metrics:\n",
    "            for key in metric_keys:\n",
    "                data[key].append(getattr(metrics, key))\n",
    "\n",
    "        fig, axes = plt.subplots(len(metric_keys), 1, figsize=(14, 20), sharex=True)\n",
    "\n",
    "        for ax, key in zip(axes, metric_keys):\n",
    "            ax.plot(time_s, data[key], label=key)\n",
    "            ax.set_ylabel(key)\n",
    "            ax.grid(True)\n",
    "            ax.legend(loc='upper left')\n",
    "\n",
    "        axes[-1].set_xlabel(\"Time (s)\")\n",
    "        fig.tight_layout()\n",
    "        if tmp_output_dir:\n",
    "            plt.savefig(os.path.join(tmp_output_dir, \"metrics_plot.png\"), dpi=300)\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def __get_available_worker(self, current_time: int) ->Optional[Worker]:\n",
    "        # FIFO\n",
    "        available_worker, min_available_at = None, float('inf')\n",
    "        for worker in self.workers:\n",
    "            if worker.is_available(current_time) and worker.available_at < min_available_at:\n",
    "                min_available_at = worker.available_at\n",
    "                available_worker = worker\n",
    "        return available_worker\n",
    "    \n",
    "    def __get_worker_init_time(self) -> int:\n",
    "        return random.randint(self.worker_init_time_min, self.worker_init_time_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006dbcd9",
   "metadata": {},
   "source": [
    "### Test cases generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5784de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def extract_continuous_segment(df, week_count, day_count, time_scale, request_scale):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', utc=True)\n",
    "    df.sort_values('timestamp', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # ËÆæÁΩÆÊó∂Èó¥Êà≥‰∏∫Á¥¢Âºï\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    # Ëé∑ÂèñÊï∞ÊçÆÁöÑËµ∑ÂßãÂíåÁªìÊùüÊó∂Èó¥\n",
    "    start_time = df.index.min()\n",
    "    end_time = df.index.max()\n",
    "\n",
    "    # ËÆ°ÁÆóÊâÄÈúÄÁöÑÊÄªÂ§©Êï∞\n",
    "    total_days = week_count * 7 + day_count\n",
    "\n",
    "    # Êü•ÊâæÊâÄÊúâÊª°Ë∂≥Êù°‰ª∂ÁöÑËøûÁª≠Êó∂Èó¥ÊÆµ\n",
    "    valid_starts = []\n",
    "    if week_count > 0:\n",
    "        # ËÆ°ÁÆóÊâÄÊúâÂèØËÉΩÁöÑÂë®‰∏Ä 00:00 ÁöÑÊó∂Èó¥ÁÇπ\n",
    "        valid_starts = pd.date_range(start=start_time, end=end_time - timedelta(days=total_days), freq='W-MON')\n",
    "    else:\n",
    "        # ËÆ°ÁÆóÊâÄÊúâÂèØËÉΩÁöÑËµ∑ÂßãÊó∂Èó¥ÁÇπ\n",
    "        valid_starts = pd.date_range(start=start_time, end=end_time - timedelta(days=total_days), freq='D')\n",
    "\n",
    "    if valid_starts.empty:\n",
    "        print(\"‚ùå Êï∞ÊçÆ‰∏≠Ê≤°ÊúâÊª°Ë∂≥Êù°‰ª∂ÁöÑËøûÁª≠Êó∂Èó¥ÊÆµ„ÄÇ\")\n",
    "        return\n",
    "\n",
    "    # ÈöèÊú∫ÈÄâÊã©‰∏Ä‰∏™Ëµ∑ÂßãÊó∂Èó¥\n",
    "    selected_start = random.choice(valid_starts)\n",
    "    selected_end = selected_start + timedelta(days=total_days)\n",
    "    print(f\"‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö{selected_start} Âà∞ {selected_end}\")\n",
    "\n",
    "    # ÊèêÂèñÈÄâ‰∏≠ÁöÑÊï∞ÊçÆÊÆµ\n",
    "    segment = df.loc[selected_start:selected_end].copy()\n",
    "    if segment.empty:\n",
    "        print(\"‚ö†Ô∏è ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÂÜÖÊ≤°ÊúâÊï∞ÊçÆ„ÄÇ\")\n",
    "        return\n",
    "\n",
    "    # ÈáçÁΩÆÊó∂Èó¥Êà≥Ôºå‰ªé 0 ÂºÄÂßãÔºåÂπ∂Â∫îÁî®Êó∂Èó¥Áº©Êîæ\n",
    "    segment.reset_index(inplace=True)\n",
    "    base_time = segment['timestamp'].min()\n",
    "    segment['timestamp'] = segment['timestamp'].apply(lambda x: int((x - base_time).total_seconds() / time_scale))\n",
    "\n",
    "    # Â∫îÁî®ËØ∑Ê±ÇÊï∞Áº©Êîæ\n",
    "    segment['requests'] = segment['requests'] / request_scale\n",
    "\n",
    "    return segment[['timestamp', 'requests']].reset_index(drop=True), base_time\n",
    "\n",
    "def schedule_requests_from_csv(requests_df, rate_df):\n",
    "    # Êâì‰π±ËØ∑Ê±ÇÈ°∫Â∫è\n",
    "    requests_df = requests_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    result_rows = []\n",
    "    request_index = 0\n",
    "    accum = 0.0  # Á¥ØÁßØÈÄüÁéá\n",
    "\n",
    "    for _, rate_row in rate_df.iterrows():\n",
    "        timestamp_base = float(rate_row['timestamp'])\n",
    "        rps = float(rate_row['requests'])\n",
    "\n",
    "        accum += rps\n",
    "        num_requests = int(accum)\n",
    "        accum -= num_requests  # ‰øùÁïôÂ∞èÊï∞ÈÉ®ÂàÜ\n",
    "\n",
    "        for _ in range(num_requests):\n",
    "            if request_index >= len(requests_df):\n",
    "                break\n",
    "            row = requests_df.iloc[request_index].copy()\n",
    "            # Âú®[T, T+1)ÂÜÖÂùáÂåÄÂàÜÂ∏É]\n",
    "            row['timestamp'] = timestamp_base + random.uniform(0, 1)\n",
    "            result_rows.append(row)\n",
    "            request_index += 1\n",
    "\n",
    "        if request_index >= len(requests_df):\n",
    "            break\n",
    "    \n",
    "    # sort by timestamp\n",
    "    result_rows.sort(key=lambda x: x['timestamp'])\n",
    "\n",
    "    # ÂàõÂª∫ÁªìÊûú DataFrame\n",
    "    return pd.DataFrame(result_rows, columns=['Id', 'Duration', 'timestamp']).rename(columns={'Id': 'id', 'Duration': 'duration'})\n",
    "\n",
    "def generate_tasks_from_csv(requests_csv_path, rate_csv_path, week_count=0, day_count=3, scale = 0.8, tmp_output_dir = None):\n",
    "    # ËØªÂèñËØ∑Ê±ÇÊï∞ÊçÆ\n",
    "    requests_df = pd.read_csv(requests_csv_path)\n",
    "    rate_df = pd.read_csv(rate_csv_path)\n",
    "\n",
    "    # ÊèêÂèñËøûÁª≠Êó∂Èó¥ÊÆµ\n",
    "    segment, base_time = extract_continuous_segment(rate_df, week_count, day_count, 120, 120 * 1 / scale)\n",
    "    if segment is None:\n",
    "        return None\n",
    "    \n",
    "    tasks_df = schedule_requests_from_csv(requests_df, segment)\n",
    "    if tasks_df is None:\n",
    "        return None\n",
    "    \n",
    "    time_start = tasks_df['timestamp'].min() \n",
    "    tasks_df['timestamp'] = tasks_df['timestamp'].apply(lambda x: int((x - time_start) * 1000))  # ËΩ¨Êç¢‰∏∫ÊØ´Áßí\n",
    "    tasks_df['id'] = tasks_df['id'].astype(int)\n",
    "    tasks_df['duration'] = tasks_df['duration'].astype(int)\n",
    "\n",
    "    if tmp_output_dir:\n",
    "        tmp_output_path = os.path.join(tmp_output_dir, 'tasks.csv')\n",
    "        if not os.path.exists(tmp_output_dir):\n",
    "            os.makedirs(tmp_output_dir)\n",
    "        tasks_df.to_csv(tmp_output_path, index=False)\n",
    "        print(f\"‚úÖ ÁîüÊàêÁöÑ‰ªªÂä°Êï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ {tmp_output_path}\")\n",
    "        # ‰øùÂ≠òbasetimeÁ≠âÂÖÉ‰ø°ÊÅØ‰∏∫jsonÊñá‰ª∂\n",
    "        meta_info = {'base_time': base_time.isoformat(), 'week_count': week_count, 'day_count': day_count, 'scale': scale}\n",
    "        meta_info_path = os.path.join(tmp_output_dir, 'meta_info.json')\n",
    "        with open(meta_info_path, 'w') as f:\n",
    "            json.dump(meta_info, f)\n",
    "        print(f\"‚úÖ ÁîüÊàêÁöÑÂÖÉÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ {meta_info_path}\")\n",
    "\n",
    "    tasks = [Task(id=row['id'], request_time=row['timestamp'], duration=row['duration']) for _, row in tasks_df.iterrows()]\n",
    "    return tasks, base_time\n",
    "\n",
    "def load_tasks_from_csv(tmp_output_dir = 'rl/tmp'):\n",
    "    tasks_df = pd.read_csv(os.path.join(tmp_output_dir, 'tasks.csv'))\n",
    "    tasks = [Task(id=row['id'], request_time=row['timestamp'], duration=row['duration']) for _, row in tasks_df.iterrows()]\n",
    "    # ËØªÂèñÂÖÉ‰ø°ÊÅØ\n",
    "    with open(os.path.join(tmp_output_dir, 'meta_info.json'), 'r') as f:\n",
    "        meta_info = json.load(f)\n",
    "        base_time = pd.to_datetime(meta_info['base_time'])\n",
    "\n",
    "    return tasks, base_time\n",
    "\n",
    "def save_metrics_to_csv(metric_history, tmp_output_dir = 'rl/tmp'):\n",
    "    os.makedirs(tmp_output_dir, exist_ok=True)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(metric_history)\n",
    "    df['time'] = df['time'].apply(lambda x: int(x / 1000)) \n",
    "    df['reward'] = df['reward'].apply(lambda x: round(x, 4))\n",
    "    df['completed_tasks'] = df['completed_tasks'].apply(lambda x: ','.join([f\"Task({t['id']}|{t['duration']}ms|{t['assigned_worker']}|{t['request_time']}-{t['start_time']}-{t['end_time']})\" for t in x]))\n",
    "\n",
    "    # Write to CSV\n",
    "    out_path = os.path.join(tmp_output_dir, 'metrics.csv')\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"‚úÖ ÁîüÊàêÁöÑÊåáÊ†áÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ {out_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7346f9",
   "metadata": {},
   "source": [
    "### Environement settings & parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5b39777",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_count = 3\n",
    "scale = 1.5\n",
    "request_mean = 3.69341263 * scale\n",
    "request_std = 2.05966675 * scale\n",
    "iterations = 60 * 12 * day_count\n",
    "init_workers = 1\n",
    "min_workers = 1\n",
    "max_workers = 6\n",
    "worker_init_time_min = 40\n",
    "worker_init_time_max = 40\n",
    "metrics_window = 10\n",
    "forecast_window = 36\n",
    "observe_length = 3\n",
    "future_length = 12\n",
    "reward_function = generate_reward_function(metrics_window * 1000, value_per_task=0.002, cost_per_worker_hour=1, delay_threshold=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ab71c14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-25 17:48:00+00:00 Âà∞ 2025-03-28 17:48:00+00:00\n",
      "‚úÖ ÁîüÊàêÁöÑ‰ªªÂä°Êï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ rl/tmp/tasks.csv\n",
      "‚úÖ ÁîüÊàêÁöÑÂÖÉÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ rl/tmp/meta_info.json\n"
     ]
    }
   ],
   "source": [
    "tasks, base_time = generate_tasks_from_csv(\n",
    "    requests_csv_path='../data/test_regression_clipped.csv',\n",
    "    rate_csv_path='../data/request_timeseries_test.csv',\n",
    "    week_count=0,\n",
    "    day_count=day_count,\n",
    "    scale=scale,\n",
    "    tmp_output_dir='rl/tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa01d6a",
   "metadata": {},
   "source": [
    "### Experiment in simulated environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4739272",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdBasedStrategy:\n",
    "    def __init__(self, \n",
    "                 min_workers: int = min_workers,\n",
    "                 max_workers: int = max_workers,\n",
    "                 aggressive_scale: bool = False,\n",
    "                 target_ongoing_tasks: int = 3, \n",
    "                 scale_up_window: int = 1, \n",
    "                 scale_down_window: int = 1):\n",
    "        self.min_workers = min_workers\n",
    "        self.max_workers = max_workers\n",
    "        self.aggressive_scale = aggressive_scale\n",
    "        self.target_ongoing_tasks = target_ongoing_tasks\n",
    "        self.scale_up_window = scale_up_window\n",
    "        self.scale_down_window = scale_down_window\n",
    "\n",
    "    def calc(self, current_expected_workers: int, metrics: List[MetricsDataPoint]) -> int:\n",
    "        if len(metrics) < self.scale_up_window or len(metrics) < self.scale_down_window:\n",
    "            return current_expected_workers\n",
    "        # Calculate the average number of ongoing tasks over the last scale_up_window iterations\n",
    "        avg_ongoing_tasks_up = np.mean([m.num_ongoing_tasks + m.num_new_tasks for m in metrics[-self.scale_up_window:]])\n",
    "        # Calculate the average number of ongoing tasks over the last scale_down_window iterations\n",
    "        avg_ongoing_tasks_down = np.mean([m.num_ongoing_tasks + m.num_new_tasks for m in metrics[-self.scale_down_window:]])\n",
    "        # Scale up if the average number of ongoing tasks is greater than the target\n",
    "        new_workers = current_expected_workers\n",
    "        running_workers = max(1, metrics[-1].active_workers)\n",
    "        if avg_ongoing_tasks_up > self.target_ongoing_tasks * running_workers:\n",
    "            new_workers = np.ceil(avg_ongoing_tasks_up / self.target_ongoing_tasks)\n",
    "            if not self.aggressive_scale and new_workers > current_expected_workers:\n",
    "                new_workers = current_expected_workers + 1\n",
    "            new_workers = min(new_workers, self.max_workers)\n",
    "\n",
    "        if avg_ongoing_tasks_down < self.target_ongoing_tasks * running_workers:\n",
    "            new_workers = np.ceil(avg_ongoing_tasks_down / self.target_ongoing_tasks)\n",
    "            if not self.aggressive_scale and new_workers < current_expected_workers:\n",
    "                new_workers = current_expected_workers - 1\n",
    "            new_workers = max(new_workers, self.min_workers)\n",
    "\n",
    "        return int(new_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76119ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§© ÊÄªreward‰∏∫Ôºö 0.5480000000000009\n",
      "‚úÖ ÁîüÊàêÁöÑÊåáÊ†áÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ rl/tmp/metrics.csv\n"
     ]
    }
   ],
   "source": [
    "strategy = ThresholdBasedStrategy(\n",
    "    min_workers=min_workers,\n",
    "    max_workers=max_workers,\n",
    "    aggressive_scale=True,\n",
    "    target_ongoing_tasks=4,\n",
    "    scale_up_window=1,\n",
    "    scale_down_window=1\n",
    ")\n",
    "tasks, _ = load_tasks_from_csv('rl/tmp')\n",
    "simulator = Simulator(tasks, init_workers, worker_init_time_min * 1000, worker_init_time_max * 1000, metrics_window * 1000,\n",
    "                      reward_function=reward_function\n",
    ")\n",
    "for i in range(iterations):\n",
    "    simulator.tick()\n",
    "    if i > 0 and i % metrics_window == 0:\n",
    "        expected_workers = strategy.calc(simulator.expected_workers, simulator.metrics)\n",
    "        simulator.scale(expected_workers)\n",
    "print(\"ü§© ÊÄªreward‰∏∫Ôºö\", sum([m.reward for m in simulator.metrics]))\n",
    "simulator.plot_metrics(\"rl/tmp\")\n",
    "save_metrics_to_csv(simulator.metrics, 'rl/tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "730a61a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "from lib.forecast.tslib_util import (\n",
    "    TimeseriesForecaster,\n",
    "    TimeseriesTransformer\n",
    ")\n",
    "\n",
    "class WorkerScaling(gym.Env):\n",
    "\n",
    "    FEATURE_MIN = {\n",
    "        \"running_workers\": 0,\n",
    "        \"new_requests\": 0,\n",
    "        \"ongoing_requests\": 0,\n",
    "        \"finished_requests\": 0,\n",
    "        \"requests_delay\": 0.0,\n",
    "        \"requests_duration\": 0.0,\n",
    "        \"forecasted_requests\": 0.0,\n",
    "    }\n",
    "\n",
    "    FEATURE_MAX = {\n",
    "        \"running_workers\": max_workers,         \n",
    "        \"new_requests\": scale * 10,            \n",
    "        \"ongoing_requests\": scale * 50,        \n",
    "        \"finished_requests\": max_workers * 6,       \n",
    "        \"requests_delay\": scale * 20000,          \n",
    "        \"requests_duration\": 12000, \n",
    "        \"forecasted_requests\": scale * 10,      \n",
    "    }\n",
    "\n",
    "    def __init__(self, config: Optional[dict] = None):\n",
    "        self.config = config or {}\n",
    "        self.observe_length = self.config.get(\"observe_length\", 36)\n",
    "        self.future_length = self.config.get(\"future_length\", 36)\n",
    "        self.action_space = Discrete(max_workers)\n",
    "        self.observation_space = Box(0.0, 1.0, shape=(self.observe_length * 6 + self.future_length,), dtype=np.float32)\n",
    "        self.time_s = 0\n",
    "\n",
    "        self.forecaster = TimeseriesForecaster()\n",
    "\n",
    "        random.seed(int(seed + self.config.get(\"worker_index\", 0)) % 99999)\n",
    "        np.random.seed(int(seed + self.config.get(\"worker_index\", 0)) % 99999)\n",
    "\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        self.init_simulator()\n",
    "        # Return obs and (empty) info dict.\n",
    "        return self.extract_observation_window(self.simulator.metrics), {\"env_state\": \"reset\"}\n",
    "\n",
    "    def step(self, action):\n",
    "        assert action in range(max_workers), f\"Invalid action {action}\"\n",
    "        \n",
    "        self.simulator.scale(action + min_workers)\n",
    "        for _ in range(metrics_window):\n",
    "            self.simulator.tick()\n",
    "            self.time_s += 1\n",
    "            if self.time_s >= iterations:\n",
    "                break\n",
    "\n",
    "        terminated = self.time_s >= iterations\n",
    "        truncated = False\n",
    "\n",
    "\n",
    "        reward = self.simulator.metrics[-1].reward\n",
    "        infos = {}\n",
    "        return (\n",
    "            self.extract_observation_window(self.simulator.metrics),\n",
    "            reward,\n",
    "            terminated,\n",
    "            truncated,\n",
    "            infos,\n",
    "        )\n",
    "    \n",
    "    def init_simulator(self, tasks=None, base_time=None):\n",
    "        if tasks is None:\n",
    "            tasks, base_time = generate_tasks_from_csv(\n",
    "                requests_csv_path='../data/train_regression_clipped.csv',\n",
    "                rate_csv_path='../data/request_timeseries_train.csv',\n",
    "                week_count=0,\n",
    "                day_count=day_count,\n",
    "                scale=scale,\n",
    "            )\n",
    "        self.simulator = Simulator(tasks, 1, worker_init_time_min* 1000, worker_init_time_max *1000, metrics_window * 1000, reward_function)\n",
    "\n",
    "        self.forecaster.setTransformer(\n",
    "            transformer=TimeseriesTransformer(\n",
    "                date_start=base_time.timestamp(), date_scale=120, scale=True,\n",
    "                scale_mean=request_mean, scale_std=request_std\n",
    "            )\n",
    "        )\n",
    "        self.time_s = 0\n",
    "        self.iteration = 0\n",
    "        self.max_iterations = len(tasks) * 2\n",
    "\n",
    "    \n",
    "    def extract_observation_window(self, data: List[MetricsDataPoint]) -> np.ndarray:\n",
    "\n",
    "        # get forecasted data\n",
    "\n",
    "        obs = np.zeros((self.observe_length * 6 + self.future_length,), dtype=np.float32)\n",
    "        if len(data) == 0:\n",
    "            return obs\n",
    "\n",
    "        if len(data) >= forecast_window:\n",
    "            forecast_metrics =  data[-forecast_window:]\n",
    "            recent_new_request = [0 if not m else m.num_new_tasks for m in forecast_metrics]\n",
    "            recent_timestamp = [self.time_s - i * metrics_window for i in range(forecast_window-1, -1, -1)]\n",
    "            future_requests = self.forecaster.forecast(\n",
    "                enc_data=recent_new_request,\n",
    "                enc_stamp=recent_timestamp,\n",
    "            )[:self.future_length]\n",
    "        else:\n",
    "            future_requests = np.zeros(self.future_length, dtype=np.float32)\n",
    "\n",
    "        # print(f\"Recent requests:{recent_new_request} \\n---\\n Forecasted future requests: {future_requests}\")\n",
    "\n",
    "        recent = data[-self.observe_length:] if len(data) >= self.observe_length else [None] * (self.observe_length - len(data)) + data\n",
    "        for i, point in enumerate(recent + list(future_requests)):\n",
    "            if point is None:\n",
    "                continue  # Keep default zeros for padding\n",
    "\n",
    "            observed = isinstance(point, MetricsDataPoint)\n",
    "            features = [\n",
    "                (\"running_workers\", point.active_workers),\n",
    "                (\"requests_delay\", point.avg_delay),\n",
    "                (\"requests_duration\", point.avg_duration),\n",
    "                (\"ongoing_requests\", point.num_ongoing_tasks),\n",
    "                (\"finished_requests\", point.num_completed_tasks),\n",
    "                (\"new_requests\", point.num_new_tasks)\n",
    "            ] if observed else [\n",
    "                (\"new_requests\", point)\n",
    "            ]\n",
    "\n",
    "            for row, (key, raw_value) in enumerate(features):\n",
    "                min_val = WorkerScaling.FEATURE_MIN[key]\n",
    "                max_val = WorkerScaling.FEATURE_MAX[key]\n",
    "                # Min-max normalization with small epsilon for safety\n",
    "                norm_val = (raw_value - min_val) / (max_val - min_val + 1e-6)\n",
    "                norm_val = np.clip(norm_val, 0.0, 1.0)\n",
    "                if i < self.observe_length:\n",
    "                    obs[row * self.observe_length + i] = norm_val\n",
    "                else:\n",
    "                    obs[6 * self.observe_length + i - self.observe_length] = norm_val\n",
    "\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c22acb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu or mps\n",
      "Use CPU\n",
      "ü§© ÊÄªreward‰∏∫Ôºö 0.7977777777777794\n",
      "‚úÖ ÁîüÊàêÁöÑÊåáÊ†áÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ rl/tmp/metrics.csv\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.core import DEFAULT_MODULE_ID\n",
    "from ray.rllib.core.columns import Columns\n",
    "from ray.rllib.core.rl_module.rl_module import RLModule\n",
    "from ray.rllib.utils.numpy import convert_to_numpy, softmax\n",
    "\n",
    "rl_module = RLModule.from_checkpoint(\n",
    "    os.path.join(\n",
    "        '/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000015',\n",
    "        \"learner_group\",\n",
    "        \"learner\",\n",
    "        \"rl_module\",\n",
    "        DEFAULT_MODULE_ID,\n",
    "    )\n",
    ")\n",
    "\n",
    "tasks, base_time = load_tasks_from_csv('rl/tmp')\n",
    "env = WorkerScaling(config={\"observe_length\": observe_length, \"future_length\": future_length,})\n",
    "env.init_simulator(tasks, base_time)\n",
    "simulator = env.simulator\n",
    "\n",
    "action = init_workers - min_workers\n",
    "while True:\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "    input_dict = {Columns.OBS: torch.from_numpy(obs).unsqueeze(0)}\n",
    "    rl_module_out = rl_module.forward_inference(input_dict)\n",
    "    logits = convert_to_numpy(rl_module_out[Columns.ACTION_DIST_INPUTS])\n",
    "    # get action with the largest probability\n",
    "    action = np.argmax(logits[0])\n",
    "\n",
    "print(\"ü§© ÊÄªreward‰∏∫Ôºö\", sum([m.reward for m in simulator.metrics]))\n",
    "save_metrics_to_csv(simulator.metrics, 'rl/tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd8a7bc",
   "metadata": {},
   "source": [
    "### Experiment in production deployment\n",
    "\n",
    "1. Run the following code to generate test for experiment\n",
    "2. change `TEST_NAME` in `experiment/env.sh` accordingly\n",
    "3. execute `experiment/benchmark-test.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c95c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_tasks_param_csv(tasks_param_csv_path, output_path, tmp_output_dir = 'rl/tmp'):\n",
    "    df_param = pd.read_csv(tasks_param_csv_path)\n",
    "    df_tasks = pd.read_csv(os.path.join(tmp_output_dir, 'tasks.csv'))\n",
    "\n",
    "    df_tasks = df_tasks[['id', 'timestamp']]\n",
    "\n",
    "    merged = pd.merge(df_param, df_tasks, on='id', how='inner')\n",
    "\n",
    "    ordered_cols = ['id', 'prompt', 'step', 'cfg', 'sampler', 'width', 'height', 'token_count', 'timestamp']\n",
    "    merged = merged[ordered_cols]\n",
    "\n",
    "    # sort by timestamp\n",
    "    merged.sort_values(by='timestamp', inplace=True)\n",
    "\n",
    "    merged.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d7e9297",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'test_longdep'\n",
    "\n",
    "merge_tasks_param_csv(\n",
    "    tasks_param_csv_path='../data/test.csv',\n",
    "    output_path=f'../experiment/input/{task_name}.csv',\n",
    "    tmp_output_dir='rl/tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55989ba6",
   "metadata": {},
   "source": [
    "### Result comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1465b642",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_deployment_result(result_csv_path):\n",
    "    df = pd.read_csv(result_csv_path)\n",
    "    column_map = {\n",
    "        'time': 'Time',\n",
    "        'expected_workers': 'Expected Worker',\n",
    "        'active_workers': 'Running Worker',\n",
    "        'total_workers': 'Total Worker',\n",
    "        'num_new_tasks': 'New Job',\n",
    "        'num_ongoing_tasks': 'Ongoing Job',\n",
    "        'num_completed_tasks': 'Completed Job',\n",
    "        'avg_duration': 'Avg Duration',\n",
    "        'avg_delay': 'Avg Delay',\n",
    "        'reward': 'Reward'\n",
    "    }\n",
    "    df = df.rename(columns=column_map)\n",
    "\n",
    "    # convert to incremental reward\n",
    "    df['Reward'] = df['Reward'].cumsum()\n",
    "\n",
    "    return df\n",
    "\n",
    "def compare_metrics(df1, df2, label1='Source 1', label2='Source 2'):\n",
    "\n",
    "    common_columns = [col for col in df1.columns if col in df2.columns and col != 'Time']\n",
    "    n = len(common_columns)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=n, ncols=1, figsize=(14, 3 * n), sharex=True)\n",
    "\n",
    "    if n == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, col in zip(axes, common_columns):\n",
    "        ax.plot(df1[\"Time\"], df1[col], label=label1)\n",
    "        ax.plot(df2[\"Time\"], df2[col], label=label2)\n",
    "        ax.set_ylabel(col)\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    axes[-1].set_xlabel(\"Time (s)\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    #save the figure\n",
    "    fig.savefig(f'rl/tmp/compare_metrics_{label1}_{label2}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad8c7d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_metrics(\n",
    "    preprocess_deployment_result('rl/tmp/metrics.csv'),\n",
    "    pd.read_csv('../experiment/result/test_longdep-rl-metrics.csv'),\n",
    "    label1='RL-simulated',\n",
    "    label2='RL-deployed'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e6d232e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_metrics(\n",
    "    pd.read_csv('../experiment/result/test_longdep-thr-metrics.csv'),\n",
    "    pd.read_csv('../experiment/result/test_longdep-rl-metrics.csv'),\n",
    "    label1='Threshold-based',\n",
    "    label2='RL-deployed'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
