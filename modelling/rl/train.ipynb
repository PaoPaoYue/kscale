{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59bb79b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c212d955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../external/tslib')\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8613f1c",
   "metadata": {},
   "source": [
    "### Simulator implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c72f3e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Task:\n",
    "    id: str\n",
    "    request_time: int\n",
    "    duration: int\n",
    "    start_time: Optional[int] = None\n",
    "    end_time: Optional[int] = None\n",
    "    assigned_worker: Optional[str] = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"Task({self.id}|{self.duration}ms|{self.assigned_worker}|{self.request_time}-{self.start_time}-{self.end_time})\"\n",
    "\n",
    "@dataclass\n",
    "class MetricsDataPoint:\n",
    "    time: int = 0\n",
    "    expected_workers: int = 0\n",
    "    active_workers: int = 0\n",
    "    total_workers: int = 0\n",
    "    num_new_tasks: int = 0\n",
    "    num_ongoing_tasks: int = 0\n",
    "    num_queued_tasks: int = 0\n",
    "    num_completed_tasks: int = 0\n",
    "    avg_delay: float = 0.0\n",
    "    avg_duration: float = 0.0\n",
    "    reward: float = 0.0\n",
    "    completed_tasks: List['Task'] = field(default_factory=list)\n",
    "    \n",
    "def generate_reward_function(metrics_window: float, value_per_task: float = 0.001, cost_per_worker_hour: float = 1, delay_threshold: int = 8000) -> float:\n",
    "    # Example reward function: negative of average delay\n",
    "    return lambda metrics: (\n",
    "        sum([0 if (task.end_time - task.request_time) > delay_threshold else value_per_task for task in metrics.completed_tasks]) -\n",
    "        cost_per_worker_hour * (metrics.total_workers * metrics_window / 3600000 )\n",
    "    )\n",
    "\n",
    "class Worker:\n",
    "    def __init__(self, init_time: int = 0):\n",
    "        self.id = \"worker-\" + str(random.randint(0, 10000))\n",
    "        self.available_at = init_time\n",
    "        self.active = False  # ÊòØÂê¶Â∑≤ÁªèÂàùÂßãÂåñÂÆåÊàê\n",
    "\n",
    "    def assign_task(self, task: Task, current_time: int):\n",
    "        if current_time < self.available_at:\n",
    "            task.start_time = self.available_at\n",
    "            self.available_at += task.duration\n",
    "        else:\n",
    "            task.start_time = current_time\n",
    "            self.available_at = current_time + task.duration\n",
    "        task.end_time = self.available_at\n",
    "        task.assigned_worker = self.id\n",
    "    \n",
    "    def is_available(self, current_time: int) -> bool:\n",
    "        return self.available_at <= current_time and self.active\n",
    "    \n",
    "\n",
    "\n",
    "class Simulator:\n",
    "    def __init__(self, tasks: List[Task], init_workers: int = 1, worker_init_time_min : int = 12000, worker_init_time_max : int = 12000, metrics_window: int = 10000, reward_function=None):\n",
    "        self.tasks = sorted(tasks, key=lambda t: t.request_time)\n",
    "        self.time = 0  \n",
    "        self.metrics_window = metrics_window\n",
    "        self.worker_init_time_min = worker_init_time_min\n",
    "        self.worker_init_time_max = worker_init_time_max\n",
    "        self.expected_workers = init_workers\n",
    "        self.workers = [Worker(self.__get_worker_init_time()) for i in range(init_workers)]\n",
    "        self.terminating_workers: List[Task] = []\n",
    "        self.in_progress: List[Task] = []\n",
    "        self.queued: List[Task] = []\n",
    "        self.completed_tasks: List[Task] = []\n",
    "\n",
    "        self.new_tasks = 0\n",
    "        self.metrics: List[MetricsDataPoint] = []\n",
    "        self.reward_function = reward_function\n",
    "\n",
    "    def tick(self): # tick 1s\n",
    "        self.time += 1000\n",
    "        # check completed tasks\n",
    "        for task in self.in_progress:\n",
    "            if task.end_time <= self.time:\n",
    "                self.completed_tasks.append(task)\n",
    "                self.in_progress.remove(task)\n",
    "        # check initialized workers\n",
    "        for w in self.workers:\n",
    "            if not w.active and self.time >= w.available_at:\n",
    "                w.active = True\n",
    "        # check terminating workers\n",
    "        self.terminating_workers = [w for w in self.terminating_workers if w.available_at >= self.time]\n",
    "        \n",
    "        worker = self.__get_available_worker(self.time)\n",
    "        # pop queued tasks\n",
    "        while worker and self.queued:\n",
    "            task = self.queued.pop(0)\n",
    "            worker.assign_task(task, task.request_time)\n",
    "            self.in_progress.append(task)\n",
    "            worker = self.__get_available_worker(self.time)\n",
    "        # pop new tasks\n",
    "        while self.tasks and self.tasks[0].request_time < self.time:\n",
    "            task = self.tasks.pop(0)\n",
    "            self.new_tasks += 1\n",
    "            if worker:\n",
    "                worker.assign_task(task, self.time)\n",
    "                self.in_progress.append(task)\n",
    "                worker = self.__get_available_worker(self.time)\n",
    "            else:\n",
    "                self.queued.append(task)\n",
    "        # report metrics\n",
    "        if self.time % self.metrics_window == 0:\n",
    "            self.report_metrics()\n",
    "\n",
    "    def scale(self, expected_workers: int):\n",
    "        if expected_workers > self.expected_workers:\n",
    "            for _ in range(expected_workers - self.expected_workers):\n",
    "                worker = Worker(self.time + self.__get_worker_init_time())\n",
    "                self.workers.append(worker)\n",
    "        elif expected_workers < self.expected_workers:\n",
    "            for _ in range(self.expected_workers - expected_workers):\n",
    "                for w in self.workers:\n",
    "                    if not w.active:\n",
    "                        worker = w\n",
    "                        self.workers.remove(worker)\n",
    "                        break\n",
    "                else:\n",
    "                    worker = self.workers.pop()\n",
    "                self.terminating_workers.append(worker)\n",
    "        self.expected_workers = expected_workers\n",
    "\n",
    "    def report_metrics(self):\n",
    "        if self.completed_tasks:\n",
    "            avg_delay = int(np.mean([t.end_time - t.request_time for t in self.completed_tasks]))\n",
    "            avg_duration = int(np.mean([t.end_time - t.start_time for t in self.completed_tasks]))\n",
    "        else:\n",
    "            avg_delay = 0\n",
    "            avg_duration = 0\n",
    "        dataPoint = MetricsDataPoint(\n",
    "            time=self.time,\n",
    "            expected_workers=self.expected_workers,\n",
    "            active_workers=len([w for w in self.workers if w.active]),\n",
    "            total_workers=len(self.workers) + len(self.terminating_workers),\n",
    "            num_new_tasks=self.new_tasks,\n",
    "            num_ongoing_tasks=len(self.in_progress) + len(self.queued),\n",
    "            num_queued_tasks=len(self.queued),\n",
    "            num_completed_tasks=len(self.completed_tasks),\n",
    "            avg_delay=avg_delay,\n",
    "            avg_duration=avg_duration,\n",
    "            completed_tasks=self.completed_tasks.copy(),\n",
    "            reward=0,  # Placeholder for reward, to be calculated later\n",
    "        )\n",
    "        if self.reward_function:\n",
    "            dataPoint.reward = self.reward_function(dataPoint)\n",
    "        self.metrics.append(dataPoint)\n",
    "        self.completed_tasks.clear()\n",
    "        self.new_tasks = 0\n",
    "        \n",
    "    def plot_metrics(self, tmp_output_dir: str = None):\n",
    "        metric_keys = [\n",
    "            'expected_workers',\n",
    "            'active_workers',\n",
    "            'total_workers',\n",
    "            'num_new_tasks',\n",
    "            'num_ongoing_tasks',\n",
    "            'num_queued_tasks',\n",
    "            'num_completed_tasks',\n",
    "            'avg_delay',\n",
    "            'avg_duration',\n",
    "            'reward'\n",
    "        ]\n",
    "\n",
    "        data = {key: [] for key in metric_keys}\n",
    "        time_s = [int(m.time / 1000) for m in self.metrics]\n",
    "\n",
    "        for metrics in self.metrics:\n",
    "            for key in metric_keys:\n",
    "                data[key].append(getattr(metrics, key))\n",
    "\n",
    "        fig, axes = plt.subplots(len(metric_keys), 1, figsize=(14, 20), sharex=True)\n",
    "\n",
    "        for ax, key in zip(axes, metric_keys):\n",
    "            ax.plot(time_s, data[key], label=key)\n",
    "            ax.set_ylabel(key)\n",
    "            ax.grid(True)\n",
    "            ax.legend(loc='upper left')\n",
    "\n",
    "        axes[-1].set_xlabel(\"Time (s)\")\n",
    "        fig.tight_layout()\n",
    "        if tmp_output_dir:\n",
    "            plt.savefig(os.path.join(tmp_output_dir, \"metrics_plot.png\"), dpi=300)\n",
    "        else:\n",
    "            plt.show()\n",
    "\n",
    "    def __get_available_worker(self, current_time: int) ->Optional[Worker]:\n",
    "        # FIFO\n",
    "        available_worker, min_available_at = None, float('inf')\n",
    "        for worker in self.workers:\n",
    "            if worker.is_available(current_time) and worker.available_at < min_available_at:\n",
    "                min_available_at = worker.available_at\n",
    "                available_worker = worker\n",
    "        return available_worker\n",
    "    \n",
    "    def __get_worker_init_time(self) -> int:\n",
    "        return random.randint(self.worker_init_time_min, self.worker_init_time_max)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e22ff4a",
   "metadata": {},
   "source": [
    "### Train/test cases generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "874aa366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "def extract_continuous_segment(df, week_count, day_count, time_scale, request_scale):\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', utc=True)\n",
    "    df.sort_values('timestamp', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # ËÆæÁΩÆÊó∂Èó¥Êà≥‰∏∫Á¥¢Âºï\n",
    "    df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    # Ëé∑ÂèñÊï∞ÊçÆÁöÑËµ∑ÂßãÂíåÁªìÊùüÊó∂Èó¥\n",
    "    start_time = df.index.min()\n",
    "    end_time = df.index.max()\n",
    "\n",
    "    # ËÆ°ÁÆóÊâÄÈúÄÁöÑÊÄªÂ§©Êï∞\n",
    "    total_days = week_count * 7 + day_count\n",
    "\n",
    "    # Êü•ÊâæÊâÄÊúâÊª°Ë∂≥Êù°‰ª∂ÁöÑËøûÁª≠Êó∂Èó¥ÊÆµ\n",
    "    valid_starts = []\n",
    "    if week_count > 0:\n",
    "        # ËÆ°ÁÆóÊâÄÊúâÂèØËÉΩÁöÑÂë®‰∏Ä 00:00 ÁöÑÊó∂Èó¥ÁÇπ\n",
    "        valid_starts = pd.date_range(start=start_time, end=end_time - timedelta(days=total_days), freq='W-MON')\n",
    "    else:\n",
    "        # ËÆ°ÁÆóÊâÄÊúâÂèØËÉΩÁöÑËµ∑ÂßãÊó∂Èó¥ÁÇπ\n",
    "        valid_starts = pd.date_range(start=start_time, end=end_time - timedelta(days=total_days), freq='D')\n",
    "\n",
    "    if valid_starts.empty:\n",
    "        print(\"‚ùå Êï∞ÊçÆ‰∏≠Ê≤°ÊúâÊª°Ë∂≥Êù°‰ª∂ÁöÑËøûÁª≠Êó∂Èó¥ÊÆµ„ÄÇ\")\n",
    "        return\n",
    "\n",
    "    # ÈöèÊú∫ÈÄâÊã©‰∏Ä‰∏™Ëµ∑ÂßãÊó∂Èó¥\n",
    "    selected_start = random.choice(valid_starts)\n",
    "    selected_end = selected_start + timedelta(days=total_days)\n",
    "    print(f\"‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö{selected_start} Âà∞ {selected_end}\")\n",
    "\n",
    "    # ÊèêÂèñÈÄâ‰∏≠ÁöÑÊï∞ÊçÆÊÆµ\n",
    "    segment = df.loc[selected_start:selected_end].copy()\n",
    "    if segment.empty:\n",
    "        print(\"‚ö†Ô∏è ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÂÜÖÊ≤°ÊúâÊï∞ÊçÆ„ÄÇ\")\n",
    "        return\n",
    "\n",
    "    # ÈáçÁΩÆÊó∂Èó¥Êà≥Ôºå‰ªé 0 ÂºÄÂßãÔºåÂπ∂Â∫îÁî®Êó∂Èó¥Áº©Êîæ\n",
    "    segment.reset_index(inplace=True)\n",
    "    base_time = segment['timestamp'].min()\n",
    "    segment['timestamp'] = segment['timestamp'].apply(lambda x: int((x - base_time).total_seconds() / time_scale))\n",
    "\n",
    "    # Â∫îÁî®ËØ∑Ê±ÇÊï∞Áº©Êîæ\n",
    "    segment['requests'] = segment['requests'] / request_scale\n",
    "\n",
    "    return segment[['timestamp', 'requests']].reset_index(drop=True), base_time\n",
    "\n",
    "def schedule_requests_from_csv(requests_df, rate_df):\n",
    "    # Êâì‰π±ËØ∑Ê±ÇÈ°∫Â∫è\n",
    "    requests_df = requests_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    result_rows = []\n",
    "    request_index = 0\n",
    "    accum = 0.0  # Á¥ØÁßØÈÄüÁéá\n",
    "\n",
    "    for _, rate_row in rate_df.iterrows():\n",
    "        timestamp_base = float(rate_row['timestamp'])\n",
    "        rps = float(rate_row['requests'])\n",
    "\n",
    "        accum += rps\n",
    "        num_requests = int(accum)\n",
    "        accum -= num_requests  # ‰øùÁïôÂ∞èÊï∞ÈÉ®ÂàÜ\n",
    "\n",
    "        for _ in range(num_requests):\n",
    "            if request_index >= len(requests_df):\n",
    "                break\n",
    "            row = requests_df.iloc[request_index].copy()\n",
    "            # Âú®[T, T+1)ÂÜÖÂùáÂåÄÂàÜÂ∏É]\n",
    "            row['timestamp'] = timestamp_base + random.uniform(0, 1)\n",
    "            result_rows.append(row)\n",
    "            request_index += 1\n",
    "\n",
    "        if request_index >= len(requests_df):\n",
    "            break\n",
    "    \n",
    "    # sort by timestamp\n",
    "    result_rows.sort(key=lambda x: x['timestamp'])\n",
    "\n",
    "    # ÂàõÂª∫ÁªìÊûú DataFrame\n",
    "    return pd.DataFrame(result_rows, columns=['Id', 'Duration', 'timestamp']).rename(columns={'Id': 'id', 'Duration': 'duration'})\n",
    "\n",
    "def generate_tasks_from_csv(requests_csv_path, rate_csv_path, week_count=0, day_count=3, scale = 0.8, tmp_output_dir = None):\n",
    "    # ËØªÂèñËØ∑Ê±ÇÊï∞ÊçÆ\n",
    "    requests_df = pd.read_csv(requests_csv_path)\n",
    "    rate_df = pd.read_csv(rate_csv_path)\n",
    "\n",
    "    # ÊèêÂèñËøûÁª≠Êó∂Èó¥ÊÆµ\n",
    "    segment, base_time = extract_continuous_segment(rate_df, week_count, day_count, 120, 120 * 1 / scale)\n",
    "    if segment is None:\n",
    "        return None\n",
    "    \n",
    "    tasks_df = schedule_requests_from_csv(requests_df, segment)\n",
    "    if tasks_df is None:\n",
    "        return None\n",
    "    \n",
    "    time_start = tasks_df['timestamp'].min() \n",
    "    tasks_df['timestamp'] = tasks_df['timestamp'].apply(lambda x: int((x - time_start) * 1000))  # ËΩ¨Êç¢‰∏∫ÊØ´Áßí\n",
    "    tasks_df['id'] = tasks_df['id'].astype(int)\n",
    "    tasks_df['duration'] = tasks_df['duration'].astype(int)\n",
    "\n",
    "    if tmp_output_dir:\n",
    "        tmp_output_path = os.path.join(tmp_output_dir, 'tasks.csv')\n",
    "        if not os.path.exists(tmp_output_dir):\n",
    "            os.makedirs(tmp_output_dir)\n",
    "        tasks_df.to_csv(tmp_output_path, index=False)\n",
    "        print(f\"‚úÖ ÁîüÊàêÁöÑ‰ªªÂä°Êï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ {tmp_output_path}\")\n",
    "        # ‰øùÂ≠òbasetimeÁ≠âÂÖÉ‰ø°ÊÅØ‰∏∫jsonÊñá‰ª∂\n",
    "        meta_info = {'base_time': base_time.isoformat(), 'week_count': week_count, 'day_count': day_count, 'scale': scale}\n",
    "        meta_info_path = os.path.join(tmp_output_dir, 'meta_info.json')\n",
    "        with open(meta_info_path, 'w') as f:\n",
    "            json.dump(meta_info, f)\n",
    "        print(f\"‚úÖ ÁîüÊàêÁöÑÂÖÉÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ {meta_info_path}\")\n",
    "\n",
    "    tasks = [Task(id=row['id'], request_time=row['timestamp'], duration=row['duration']) for _, row in tasks_df.iterrows()]\n",
    "    return tasks, base_time\n",
    "\n",
    "def load_tasks_from_csv(tmp_output_dir = 'rl/tmp'):\n",
    "    tasks_df = pd.read_csv(os.path.join(tmp_output_dir, 'tasks.csv'))\n",
    "    tasks = [Task(id=row['id'], request_time=row['timestamp'], duration=row['duration']) for _, row in tasks_df.iterrows()]\n",
    "    # ËØªÂèñÂÖÉ‰ø°ÊÅØ\n",
    "    with open(os.path.join(tmp_output_dir, 'meta_info.json'), 'r') as f:\n",
    "        meta_info = json.load(f)\n",
    "        base_time = pd.to_datetime(meta_info['base_time'])\n",
    "\n",
    "    return tasks, base_time\n",
    "\n",
    "def save_metrics_to_csv(metric_history, tmp_output_dir = 'rl/tmp'):\n",
    "    os.makedirs(tmp_output_dir, exist_ok=True)\n",
    "\n",
    "    # Build DataFrame\n",
    "    df = pd.DataFrame(metric_history)\n",
    "    df['time'] = df['time'].apply(lambda x: int(x / 1000)) \n",
    "    df['reward'] = df['reward'].apply(lambda x: round(x, 4))\n",
    "    df['completed_tasks'] = df['completed_tasks'].apply(lambda x: ','.join([f\"Task({t['id']}|{t['duration']}ms|{t['assigned_worker']}|{t['request_time']}-{t['start_time']}-{t['end_time']})\" for t in x]))\n",
    "\n",
    "    # Write to CSV\n",
    "    out_path = os.path.join(tmp_output_dir, 'metrics.csv')\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f\"‚úÖ ÁîüÊàêÁöÑÊåáÊ†áÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ {out_path}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f5753b",
   "metadata": {},
   "source": [
    "### Environement settings & parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d56a7ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "day_count = 3\n",
    "scale = 1.5\n",
    "request_mean = 3.69341263 * scale\n",
    "request_std = 2.05966675 * scale\n",
    "iterations = 60 * 12 * day_count\n",
    "init_workers = 1\n",
    "min_workers = 1\n",
    "max_workers = 6\n",
    "worker_init_time_min = 40\n",
    "worker_init_time_max = 40\n",
    "metrics_window = 10\n",
    "forecast_window = 36\n",
    "observe_length = 3\n",
    "future_length = 12\n",
    "reward_function = generate_reward_function(metrics_window * 1000, value_per_task=0.002, cost_per_worker_hour=1, delay_threshold=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e55fe19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-17 17:48:00+00:00 Âà∞ 2025-03-20 17:48:00+00:00\n",
      "‚úÖ ÁîüÊàêÁöÑ‰ªªÂä°Êï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ rl/tmp/tasks.csv\n",
      "‚úÖ ÁîüÊàêÁöÑÂÖÉÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ rl/tmp/meta_info.json\n"
     ]
    }
   ],
   "source": [
    "tasks, base_time = generate_tasks_from_csv(\n",
    "    requests_csv_path='../data/test_regression_clipped.csv',\n",
    "    rate_csv_path='../data/request_timeseries_test.csv',\n",
    "    week_count=0,\n",
    "    day_count=day_count,\n",
    "    scale=scale,\n",
    "    tmp_output_dir='rl/tmp'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224b9171",
   "metadata": {},
   "source": [
    "### No scaling baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3013308c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§© ÊÄªreward‰∏∫Ôºö -0.5339999999999987\n",
      "‚úÖ ÁîüÊàêÁöÑÊåáÊ†áÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ rl/tmp/metrics.csv\n"
     ]
    }
   ],
   "source": [
    "tasks, _ = load_tasks_from_csv('rl/tmp')\n",
    "simulator = Simulator(tasks, 1, worker_init_time_min * 1000, worker_init_time_max * 1000, metrics_window * 1000,\n",
    "                      reward_function=reward_function\n",
    ")\n",
    "for i in range(iterations):\n",
    "    simulator.tick()\n",
    "\n",
    "print(\"ü§© ÊÄªreward‰∏∫Ôºö\", sum([m.reward for m in simulator.metrics]))\n",
    "simulator.plot_metrics(\"rl/tmp\")\n",
    "save_metrics_to_csv(simulator.metrics, 'rl/tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd7b6fe",
   "metadata": {},
   "source": [
    "### Threshold based scaling baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ea897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThresholdBasedStrategy:\n",
    "    def __init__(self, \n",
    "                 min_workers: int = min_workers,\n",
    "                 max_workers: int = max_workers,\n",
    "                 aggressive_scale: bool = False,\n",
    "                 target_ongoing_tasks: int = 3, \n",
    "                 scale_up_window: int = 1, \n",
    "                 scale_down_window: int = 1):\n",
    "        self.min_workers = min_workers\n",
    "        self.max_workers = max_workers\n",
    "        self.aggressive_scale = aggressive_scale\n",
    "        self.target_ongoing_tasks = target_ongoing_tasks\n",
    "        self.scale_up_window = scale_up_window\n",
    "        self.scale_down_window = scale_down_window\n",
    "\n",
    "    def calc(self, current_expected_workers: int, metrics: List[MetricsDataPoint]) -> int:\n",
    "        if len(metrics) < self.scale_up_window or len(metrics) < self.scale_down_window:\n",
    "            return current_expected_workers\n",
    "        # Calculate the average number of ongoing tasks over the last scale_up_window iterations\n",
    "        avg_ongoing_tasks_up = np.mean([m.num_ongoing_tasks + m.num_new_tasks for m in metrics[-self.scale_up_window:]])\n",
    "        # Calculate the average number of ongoing tasks over the last scale_down_window iterations\n",
    "        avg_ongoing_tasks_down = np.mean([m.num_ongoing_tasks + m.num_new_tasks for m in metrics[-self.scale_down_window:]])\n",
    "        # Scale up if the average number of ongoing tasks is greater than the target\n",
    "        new_workers = current_expected_workers\n",
    "        running_workers = max(1, metrics[-1].active_workers)\n",
    "        if avg_ongoing_tasks_up > self.target_ongoing_tasks * running_workers:\n",
    "            new_workers = np.ceil(avg_ongoing_tasks_up / self.target_ongoing_tasks)\n",
    "            if not self.aggressive_scale and new_workers > current_expected_workers:\n",
    "                new_workers = current_expected_workers + 1\n",
    "            new_workers = min(new_workers, self.max_workers)\n",
    "\n",
    "        if avg_ongoing_tasks_down < self.target_ongoing_tasks * running_workers:\n",
    "            new_workers = np.ceil(avg_ongoing_tasks_down / self.target_ongoing_tasks)\n",
    "            if not self.aggressive_scale and new_workers < current_expected_workers:\n",
    "                new_workers = current_expected_workers - 1\n",
    "            new_workers = max(new_workers, self.min_workers)\n",
    "\n",
    "        return int(new_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48520b7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§© ÊÄªreward‰∏∫Ôºö 0.32877777777777806\n",
      "‚úÖ ÁîüÊàêÁöÑÊåáÊ†áÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ rl/tmp/metrics.csv\n"
     ]
    }
   ],
   "source": [
    "strategy = ThresholdBasedStrategy(\n",
    "    min_workers=min_workers,\n",
    "    max_workers=max_workers,\n",
    "    aggressive_scale=True,\n",
    "    target_ongoing_tasks=4,\n",
    "    scale_up_window=1,\n",
    "    scale_down_window=1\n",
    ")\n",
    "tasks, _ = load_tasks_from_csv('rl/tmp')\n",
    "simulator = Simulator(tasks, init_workers, worker_init_time_min * 1000, worker_init_time_max * 1000, metrics_window * 1000,\n",
    "                      reward_function=reward_function\n",
    ")\n",
    "for i in range(iterations):\n",
    "    simulator.tick()\n",
    "    if i > 0 and i % metrics_window == 0:\n",
    "        expected_workers = strategy.calc(simulator.expected_workers, simulator.metrics)\n",
    "        simulator.scale(expected_workers)\n",
    "print(\"ü§© ÊÄªreward‰∏∫Ôºö\", sum([m.reward for m in simulator.metrics]))\n",
    "simulator.plot_metrics(\"rl/tmp\")\n",
    "save_metrics_to_csv(simulator.metrics, 'rl/tmp')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c79f1e",
   "metadata": {},
   "source": [
    "### RL Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37b3b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import gymnasium as gym\n",
    "from gymnasium.spaces import Discrete, Box\n",
    "from lib.forecast.tslib_util import (\n",
    "    TimeseriesForecaster,\n",
    "    TimeseriesTransformer\n",
    ")\n",
    "\n",
    "class WorkerScaling(gym.Env):\n",
    "\n",
    "    FEATURE_MIN = {\n",
    "        \"running_workers\": 0,\n",
    "        \"new_requests\": 0,\n",
    "        \"ongoing_requests\": 0,\n",
    "        \"finished_requests\": 0,\n",
    "        \"requests_delay\": 0.0,\n",
    "        \"requests_duration\": 0.0,\n",
    "        \"forecasted_requests\": 0.0,\n",
    "    }\n",
    "\n",
    "    FEATURE_MAX = {\n",
    "        \"running_workers\": max_workers,         \n",
    "        \"new_requests\": scale * 10,            \n",
    "        \"ongoing_requests\": scale * 50,        \n",
    "        \"finished_requests\": max_workers * 6,       \n",
    "        \"requests_delay\": scale * 20000,          \n",
    "        \"requests_duration\": 12000, \n",
    "        \"forecasted_requests\": scale * 10,      \n",
    "    }\n",
    "\n",
    "    def __init__(self, config: Optional[dict] = None):\n",
    "        self.config = config or {}\n",
    "        self.observe_length = self.config.get(\"observe_length\", 36)\n",
    "        self.future_length = self.config.get(\"future_length\", 36)\n",
    "        self.action_space = Discrete(max_workers)\n",
    "        self.observation_space = Box(0.0, 1.0, shape=(self.observe_length * 6 + self.future_length,), dtype=np.float32)\n",
    "        self.time_s = 0\n",
    "\n",
    "        self.forecaster = TimeseriesForecaster()\n",
    "\n",
    "        random.seed(int(seed + self.config.get(\"worker_index\", 0)) % 99999)\n",
    "        np.random.seed(int(seed + self.config.get(\"worker_index\", 0)) % 99999)\n",
    "\n",
    "\n",
    "    def reset(self, *, seed=None, options=None):\n",
    "        self.init_simulator()\n",
    "        # Return obs and (empty) info dict.\n",
    "        return self.extract_observation_window(self.simulator.metrics), {\"env_state\": \"reset\"}\n",
    "\n",
    "    def step(self, action):\n",
    "        assert action in range(max_workers), f\"Invalid action {action}\"\n",
    "        \n",
    "        self.simulator.scale(action + min_workers)\n",
    "        for _ in range(metrics_window):\n",
    "            self.simulator.tick()\n",
    "            self.time_s += 1\n",
    "            if self.time_s >= iterations:\n",
    "                break\n",
    "\n",
    "        terminated = self.time_s >= iterations\n",
    "        truncated = False\n",
    "\n",
    "\n",
    "        reward = self.simulator.metrics[-1].reward\n",
    "        infos = {}\n",
    "        return (\n",
    "            self.extract_observation_window(self.simulator.metrics),\n",
    "            reward,\n",
    "            terminated,\n",
    "            truncated,\n",
    "            infos,\n",
    "        )\n",
    "    \n",
    "    def init_simulator(self, tasks=None, base_time=None):\n",
    "        if tasks is None:\n",
    "            tasks, base_time = generate_tasks_from_csv(\n",
    "                requests_csv_path='../data/train_regression_clipped.csv',\n",
    "                rate_csv_path='../data/request_timeseries_train.csv',\n",
    "                week_count=0,\n",
    "                day_count=day_count,\n",
    "                scale=scale,\n",
    "            )\n",
    "        self.simulator = Simulator(tasks, 1, worker_init_time_min* 1000, worker_init_time_max *1000, metrics_window * 1000, reward_function)\n",
    "\n",
    "        self.forecaster.setTransformer(\n",
    "            transformer=TimeseriesTransformer(\n",
    "                date_start=base_time.timestamp(), date_scale=120, scale=True,\n",
    "                scale_mean=request_mean, scale_std=request_std\n",
    "            )\n",
    "        )\n",
    "        self.time_s = 0\n",
    "        self.iteration = 0\n",
    "        self.max_iterations = len(tasks) * 2\n",
    "\n",
    "    \n",
    "    def extract_observation_window(self, data: List[MetricsDataPoint]) -> np.ndarray:\n",
    "\n",
    "        # get forecasted data\n",
    "\n",
    "        obs = np.zeros((self.observe_length * 6 + self.future_length,), dtype=np.float32)\n",
    "        if len(data) == 0:\n",
    "            return obs\n",
    "\n",
    "        if len(data) >= forecast_window:\n",
    "            forecast_metrics =  data[-forecast_window:]\n",
    "            recent_new_request = [0 if not m else m.num_new_tasks for m in forecast_metrics]\n",
    "            recent_timestamp = [self.time_s - i * metrics_window for i in range(forecast_window-1, -1, -1)]\n",
    "            future_requests = self.forecaster.forecast(\n",
    "                enc_data=recent_new_request,\n",
    "                enc_stamp=recent_timestamp,\n",
    "            )[:self.future_length]\n",
    "        else:\n",
    "            future_requests = np.zeros(self.future_length, dtype=np.float32)\n",
    "\n",
    "        # print(f\"Recent requests:{recent_new_request} \\n---\\n Forecasted future requests: {future_requests}\")\n",
    "\n",
    "        recent = data[-self.observe_length:] if len(data) >= self.observe_length else [None] * (self.observe_length - len(data)) + data\n",
    "        for i, point in enumerate(recent + list(future_requests)):\n",
    "            if point is None:\n",
    "                continue  # Keep default zeros for padding\n",
    "\n",
    "            observed = isinstance(point, MetricsDataPoint)\n",
    "            features = [\n",
    "                (\"running_workers\", point.active_workers),\n",
    "                (\"requests_delay\", point.avg_delay),\n",
    "                (\"requests_duration\", point.avg_duration),\n",
    "                (\"ongoing_requests\", point.num_ongoing_tasks),\n",
    "                (\"finished_requests\", point.num_completed_tasks),\n",
    "                (\"new_requests\", point.num_new_tasks)\n",
    "            ] if observed else [\n",
    "                (\"new_requests\", point)\n",
    "            ]\n",
    "\n",
    "            for row, (key, raw_value) in enumerate(features):\n",
    "                min_val = WorkerScaling.FEATURE_MIN[key]\n",
    "                max_val = WorkerScaling.FEATURE_MAX[key]\n",
    "                # Min-max normalization with small epsilon for safety\n",
    "                norm_val = (raw_value - min_val) / (max_val - min_val + 1e-6)\n",
    "                norm_val = np.clip(norm_val, 0.0, 1.0)\n",
    "                if i < self.observe_length:\n",
    "                    obs[row * self.observe_length + i] = norm_val\n",
    "                else:\n",
    "                    obs[6 * self.observe_length + i - self.observe_length] = norm_val\n",
    "\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14742fbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 02:43:09,151\tINFO worker.py:1888 -- Started a local Ray instance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-06-26 05:04:39</td></tr>\n",
       "<tr><td>Running for: </td><td>02:21:27.86        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.0/15.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.8000000000000007/8 CPUs, 1.0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>status    </th><th>loc                </th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  num_training_step_ca\n",
       "lls_per_iteration</th><th style=\"text-align: right;\">       num_env_steps_sample\n",
       "d_lifetime</th><th style=\"text-align: right;\">        ...env_steps_sampled\n",
       "_lifetime_throughput</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WorkerScaling_3efe5_00000</td><td>TERMINATED</td><td>192.168.0.103:15632</td><td style=\"text-align: right;\">   200</td><td style=\"text-align: right;\">         8405.77</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">400000</td><td style=\"text-align: right;\">46.0906</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 02:43:12,076\tWARNING algorithm_config.py:4766 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n",
      "\u001b[36m(PPO pid=15632)\u001b[0m 2025-06-26 02:43:27,658\tWARNING algorithm_config.py:4766 -- You are running PPO on the new API stack! This is the new default behavior for this algorithm. If you don't want to use the new API stack, set `config.api_stack(enable_rl_module_and_learner=False,enable_env_runner_and_connector_v2=False)`. For a detailed migration guide, see here: https://docs.ray.io/en/master/rllib/new-api-stack-migration-guide.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m Using cpu or mps\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m Use CPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m 2025-06-26 02:44:02,981\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\n",
      "\u001b[36m(PPO pid=15632)\u001b[0m Trainable.setup took 39.459 seconds. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n",
      "\u001b[36m(PPO pid=15632)\u001b[0m Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-05 13:00:00+00:00 Âà∞ 2025-01-08 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15699)\u001b[0m Using cpu or mps\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15699)\u001b[0m Use CPU\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-25 13:00:00+00:00 Âà∞ 2025-01-28 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-24 13:00:00+00:00 Âà∞ 2024-12-27 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step994 Âπ≥Âùáreward‰∏∫ -2.6842777777777727\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                   </th><th>env_runner_group                               </th><th>env_runners                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  </th><th>fault_tolerance                                            </th><th>learners                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      </th><th style=\"text-align: right;\">  num_env_steps_sampled_lifetime</th><th style=\"text-align: right;\">  num_env_steps_sampled_lifetime_throughput</th><th style=\"text-align: right;\">  num_training_step_calls_per_iteration</th><th>perf                                                                                                  </th><th>timers                                                                                                                                                                                                                                                                                                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>PPO_WorkerScaling_3efe5_00000</td><td>{&#x27;actor_manager_num_outstanding_async_reqs&#x27;: 0}</td><td>{&#x27;episode_return_min&#x27;: 0.2627777777777777, &#x27;module_to_env_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;remove_single_ts_time_rank_from_batch&#x27;: np.float64(1.2484567710691035e-05), &#x27;get_actions&#x27;: np.float64(0.0010395520389616141), &#x27;un_batch_to_individual_items&#x27;: np.float64(0.00010400964541281775), &#x27;tensor_to_numpy&#x27;: np.float64(0.0003316935901084214), &#x27;listify_data_for_vector_env&#x27;: np.float64(0.00019797636640048923), &#x27;normalize_and_clip_actions&#x27;: np.float64(0.00016861652724151264)}}, &#x27;connector_pipeline_timer&#x27;: np.float64(0.0023264949618258136)}, &#x27;num_episodes_lifetime&#x27;: 1848, &#x27;env_to_module_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;batch_individual_items&#x27;: np.float64(0.00014173326620110392), &#x27;add_states_from_episodes_to_batch&#x27;: np.float64(2.9620088335786173e-05), &#x27;numpy_to_tensor&#x27;: np.float64(0.00023094151539839982), &#x27;add_time_dim_to_batch_and_zero_pad&#x27;: np.float64(4.977403328423932e-05), &#x27;add_observations_from_episodes_to_batch&#x27;: np.float64(5.456656158560829e-05)}}, &#x27;connector_pipeline_timer&#x27;: np.float64(0.0008697904591026213)}, &#x27;episode_return_mean&#x27;: 0.4654903846153849, &#x27;num_module_steps_sampled&#x27;: {&#x27;default_policy&#x27;: 2000}, &#x27;episode_len_min&#x27;: 216, &#x27;num_module_steps_sampled_lifetime&#x27;: {&#x27;default_policy&#x27;: 400000}, &#x27;episode_return_max&#x27;: 0.6788888888888903, &#x27;env_step_timer&#x27;: np.float64(0.09866154293952545), &#x27;env_to_module_sum_episodes_length_out&#x27;: np.float64(93.80785496779632), &#x27;num_env_steps_sampled&#x27;: 2000, &#x27;sample&#x27;: np.float64(26.775864138154944), &#x27;episode_len_max&#x27;: 216, &#x27;env_reset_timer&#x27;: np.float64(4.086234589500236), &#x27;num_agent_steps_sampled&#x27;: {&#x27;default_agent&#x27;: 2000}, &#x27;num_agent_steps_sampled_lifetime&#x27;: {&#x27;default_agent&#x27;: 400000}, &#x27;episode_duration_sec_mean&#x27;: 19.739570516201567, &#x27;module_episode_returns_mean&#x27;: {&#x27;default_policy&#x27;: 0.4654903846153849}, &#x27;rlmodule_inference_timer&#x27;: np.float64(0.000801781817147362), &#x27;num_env_steps_sampled_lifetime&#x27;: 400000, &#x27;num_episodes&#x27;: 8, &#x27;agent_episode_returns_mean&#x27;: {&#x27;default_agent&#x27;: 0.4654903846153849}, &#x27;episode_len_mean&#x27;: 216.0, &#x27;weights_seq_no&#x27;: 199.0, &#x27;env_to_module_sum_episodes_length_in&#x27;: np.float64(93.80785496779632), &#x27;time_between_sampling&#x27;: np.float64(16.035366306382283), &#x27;num_env_steps_sampled_lifetime_throughput&#x27;: 46.09064447532183}</td><td>{&#x27;num_healthy_workers&#x27;: 8, &#x27;num_remote_worker_restarts&#x27;: 0}</td><td>{&#x27;__all_modules__&#x27;: {&#x27;learner_connector_sum_episodes_length_out&#x27;: 2016.713326666458, &#x27;learner_connector&#x27;: {&#x27;timers&#x27;: {&#x27;connectors&#x27;: {&#x27;add_time_dim_to_batch_and_zero_pad&#x27;: 6.042930834671405e-05, &#x27;add_columns_from_episodes_to_train_batch&#x27;: 0.15351716896353948, &#x27;add_observations_from_episodes_to_batch&#x27;: 0.0007016455922639428, &#x27;add_one_ts_to_episodes_and_truncate&#x27;: 0.011680853215531299, &#x27;batch_individual_items&#x27;: 0.08953169527979005, &#x27;general_advantage_estimation&#x27;: 0.11234784374764584, &#x27;add_states_from_episodes_to_batch&#x27;: 2.0264874019747135e-05, &#x27;numpy_to_tensor&#x27;: 0.0019945028075147517}}, &#x27;connector_pipeline_timer&#x27;: 0.37065784284398284}, &#x27;num_env_steps_trained_lifetime&#x27;: 190948560, &#x27;num_trainable_parameters&#x27;: 75527.0, &#x27;num_env_steps_trained&#x27;: 953568, &#x27;num_module_steps_trained&#x27;: 60544, &#x27;learner_connector_sum_episodes_length_in&#x27;: 2000.0, &#x27;num_non_trainable_parameters&#x27;: 0.0, &#x27;num_module_steps_trained_lifetime&#x27;: 12116480, &#x27;num_env_steps_trained_lifetime_throughput&#x27;: 0.0}, &#x27;default_policy&#x27;: {&#x27;num_module_steps_trained_lifetime&#x27;: 12116480, &#x27;diff_num_grad_updates_vs_sampler_policy&#x27;: np.float32(1.0), &#x27;weights_seq_no&#x27;: 200.0, &#x27;vf_loss&#x27;: np.float32(0.0025301585), &#x27;curr_kl_coeff&#x27;: 0.5406097769737244, &#x27;curr_entropy_coeff&#x27;: 0.0, &#x27;module_train_batch_size_mean&#x27;: 128.0, &#x27;policy_loss&#x27;: np.float32(-0.14330462), &#x27;default_optimizer_learning_rate&#x27;: 0.0003, &#x27;total_loss&#x27;: np.float32(-0.1362771), &#x27;num_trainable_parameters&#x27;: 75527.0, &#x27;entropy&#x27;: np.float32(0.3078108), &#x27;vf_explained_var&#x27;: np.float32(0.38390273), &#x27;mean_kl_loss&#x27;: np.float32(0.008319024), &#x27;num_module_steps_trained&#x27;: 60544, &#x27;vf_loss_unclipped&#x27;: np.float32(0.0025301585), &#x27;gradients_default_optimizer_global_norm&#x27;: np.float32(1.9911885)}}</td><td style=\"text-align: right;\">                          400000</td><td style=\"text-align: right;\">                                    46.0906</td><td style=\"text-align: right;\">                                      1</td><td>{&#x27;cpu_util_percent&#x27;: np.float64(69.7573770491803), &#x27;ram_util_percent&#x27;: np.float64(57.954098360655735)}</td><td>{&#x27;training_iteration&#x27;: 42.70518487694511, &#x27;restore_env_runners&#x27;: 4.407265012087706e-05, &#x27;training_step&#x27;: 42.704281871117566, &#x27;env_runner_sampling_timer&#x27;: 28.472219710304763, &#x27;learner_update_timer&#x27;: 14.219490902018416, &#x27;synch_weights&#x27;: 0.010916667453998026, &#x27;synch_env_connectors&#x27;: 0.013966295704162671}</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-24 13:00:00+00:00 Âà∞ 2025-01-27 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-06 13:00:00+00:00 Âà∞ 2025-01-09 13:00:00+00:00\n",
      "ü§© step1414 Âπ≥Âùáreward‰∏∫ -2.7379273504273454\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-04 13:00:00+00:00 Âà∞ 2025-02-07 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step1827 Âπ≥Âùáreward‰∏∫ -2.6391335470085426\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-03 13:00:00+00:00 Âà∞ 2025-03-06 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step2248 Âπ≥Âùáreward‰∏∫ -2.6228408119658084\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-12 13:00:00+00:00 Âà∞ 2025-03-15 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step2659 Âπ≥Âùáreward‰∏∫ -2.4404326923076898\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-18 13:00:00+00:00 Âà∞ 2025-02-21 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step3080 Âπ≥Âùáreward‰∏∫ -2.248246794871792\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-24 13:00:00+00:00 Âà∞ 2025-02-27 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15699)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-01 13:00:00+00:00 Âà∞ 2025-02-04 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step3523 Âπ≥Âùáreward‰∏∫ -2.2548076923076876\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-01 13:00:00+00:00 Âà∞ 2025-01-04 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step3921 Âπ≥Âùáreward‰∏∫ -1.9202489316239275\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-24 13:00:00+00:00 Âà∞ 2024-12-27 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step4338 Âπ≥Âùáreward‰∏∫ -1.648606837606836\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-08 13:00:00+00:00 Âà∞ 2025-02-11 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step4750 Âπ≥Âùáreward‰∏∫ -1.5299049145299137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000000)\n",
      "\u001b[36m(PPO pid=15632)\u001b[0m 2025-06-26 02:44:06,896\tWARNING deprecation.py:50 -- DeprecationWarning: `RLModule(config=[RLModuleConfig object])` has been deprecated. Use `RLModule(observation_space=.., action_space=.., inference_only=.., model_config=.., catalog_class=..)` instead. This will raise an error in the future!\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-20 13:00:00+00:00 Âà∞ 2025-01-23 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step5171 Âπ≥Âùáreward‰∏∫ -1.3819038461538458\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-11 13:00:00+00:00 Âà∞ 2025-03-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step5589 Âπ≥Âùáreward‰∏∫ -1.1983354700854691\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-21 13:00:00+00:00 Âà∞ 2025-02-24 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-22 13:00:00+00:00 Âà∞ 2025-01-25 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step6040 Âπ≥Âùáreward‰∏∫ -0.9596709401709392\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-13 13:00:00+00:00 Âà∞ 2025-01-16 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step6458 Âπ≥Âùáreward‰∏∫ -0.8868087606837604\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-20 13:00:00+00:00 Âà∞ 2025-02-23 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step6873 Âπ≥Âùáreward‰∏∫ -0.767819444444444\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-06 13:00:00+00:00 Âà∞ 2025-02-09 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step7259 Âπ≥Âùáreward‰∏∫ -0.5925865384615382\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-18 13:00:00+00:00 Âà∞ 2025-01-21 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step7650 Âπ≥Âùáreward‰∏∫ -0.5369914529914527\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-07 13:00:00+00:00 Âà∞ 2025-01-10 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step8040 Âπ≥Âùáreward‰∏∫ -0.6160651709401704\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-24 13:00:00+00:00 Âà∞ 2025-02-27 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step8420 Âπ≥Âùáreward‰∏∫ -0.5971549145299141\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-23 13:00:00+00:00 Âà∞ 2025-01-26 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-24 13:00:00+00:00 Âà∞ 2024-12-27 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-08 13:00:00+00:00 Âà∞ 2025-01-11 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step8829 Âπ≥Âùáreward‰∏∫ -0.34975641025640986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000001)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-25 13:00:00+00:00 Âà∞ 2025-02-28 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-08 13:00:00+00:00 Âà∞ 2025-02-11 13:00:00+00:00\n",
      "ü§© step9232 Âπ≥Âùáreward‰∏∫ -0.3771645299145297\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-23 13:00:00+00:00 Âà∞ 2024-12-26 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step9638 Âπ≥Âùáreward‰∏∫ -0.2658514957264955\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-08 13:00:00+00:00 Âà∞ 2025-03-11 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step10043 Âπ≥Âùáreward‰∏∫ -0.297744658119658\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-11 13:00:00+00:00 Âà∞ 2025-01-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step10439 Âπ≥Âùáreward‰∏∫ -0.2434743589743589\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-10 13:00:00+00:00 Âà∞ 2025-01-13 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step10832 Âπ≥Âùáreward‰∏∫ -0.19662286324786316\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-07 13:00:00+00:00 Âà∞ 2025-01-10 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15706)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-02 13:00:00+00:00 Âà∞ 2025-02-05 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step11264 Âπ≥Âùáreward‰∏∫ -0.15804807692307687\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-04 13:00:00+00:00 Âà∞ 2025-01-07 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step11653 Âπ≥Âùáreward‰∏∫ -0.11933119658119645\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-23 13:00:00+00:00 Âà∞ 2025-01-26 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step12061 Âπ≥Âùáreward‰∏∫ -0.028717948717948576\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15699)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-08 13:00:00+00:00 Âà∞ 2025-03-11 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step12479 Âπ≥Âùáreward‰∏∫ 0.08431303418803446\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-10 13:00:00+00:00 Âà∞ 2025-01-13 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step12916 Âπ≥Âùáreward‰∏∫ 0.05458547008547021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000002)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-11 13:00:00+00:00 Âà∞ 2025-01-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step13348 Âπ≥Âùáreward‰∏∫ -0.0019155982905982348\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-23 13:00:00+00:00 Âà∞ 2024-12-26 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15699)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-05 13:00:00+00:00 Âà∞ 2025-01-08 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-22 13:00:00+00:00 Âà∞ 2025-02-25 13:00:00+00:00\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "ü§© step13877 Âπ≥Âùáreward‰∏∫ 0.0798098290598291\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-26 13:00:00+00:00 Âà∞ 2025-03-01 13:00:00+00:00\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "ü§© step14370 Âπ≥Âùáreward‰∏∫ 0.1025160256410257\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-11 13:00:00+00:00 Âà∞ 2025-02-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-28 13:00:00+00:00 Âà∞ 2025-03-03 13:00:00+00:00\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "ü§© step14835 Âπ≥Âùáreward‰∏∫ 0.12798931623931634\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-21 13:00:00+00:00 Âà∞ 2025-02-24 13:00:00+00:00\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-26 13:00:00+00:00 Âà∞ 2024-12-29 13:00:00+00:00\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "ü§© step15305 Âπ≥Âùáreward‰∏∫ 0.12335790598290602\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15706)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-24 13:00:00+00:00 Âà∞ 2025-02-27 13:00:00+00:00\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-06 13:00:00+00:00 Âà∞ 2025-02-09 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step15843 Âπ≥Âùáreward‰∏∫ 0.2093525641025643\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-09 13:00:00+00:00 Âà∞ 2025-02-12 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-13 13:00:00+00:00 Âà∞ 2025-02-16 13:00:00+00:00\n",
      "ü§© step16397 Âπ≥Âùáreward‰∏∫ 0.19331303418803428\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-31 13:00:00+00:00 Âà∞ 2025-01-03 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step16807 Âπ≥Âùáreward‰∏∫ 0.22163461538461543\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-05 13:00:00+00:00 Âà∞ 2025-03-08 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-25 13:00:00+00:00 Âà∞ 2025-02-28 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-02 13:00:00+00:00 Âà∞ 2025-02-05 13:00:00+00:00\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "ü§© step17235 Âπ≥Âùáreward‰∏∫ 0.31787606837606847\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-17 13:00:00+00:00 Âà∞ 2025-02-20 13:00:00+00:00\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "ü§© step17632 Âπ≥Âùáreward‰∏∫ 0.29303739316239336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000003)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-07 13:00:00+00:00 Âà∞ 2025-02-10 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step18039 Âπ≥Âùáreward‰∏∫ 0.2686826923076925\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-27 13:00:00+00:00 Âà∞ 2025-01-30 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step18445 Âπ≥Âùáreward‰∏∫ 0.27697970085470086\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-05 13:00:00+00:00 Âà∞ 2025-01-08 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step18847 Âπ≥Âùáreward‰∏∫ 0.2998461538461539\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-08 13:00:00+00:00 Âà∞ 2025-03-11 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step19248 Âπ≥Âùáreward‰∏∫ 0.29342521367521374\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-05 13:00:00+00:00 Âà∞ 2025-02-08 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-06 13:00:00+00:00 Âà∞ 2025-02-09 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step19673 Âπ≥Âùáreward‰∏∫ 0.2724038461538462\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-25 13:00:00+00:00 Âà∞ 2025-02-28 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step20062 Âπ≥Âùáreward‰∏∫ 0.2958664529914531\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-20 13:00:00+00:00 Âà∞ 2025-02-23 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step20462 Âπ≥Âùáreward‰∏∫ 0.35428311965812015\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-26 13:00:00+00:00 Âà∞ 2024-12-29 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step20868 Âπ≥Âùáreward‰∏∫ 0.3614529914529918\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-17 13:00:00+00:00 Âà∞ 2025-01-20 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step21275 Âπ≥Âùáreward‰∏∫ 0.3493472222222223\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-27 13:00:00+00:00 Âà∞ 2025-01-30 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step21672 Âπ≥Âùáreward‰∏∫ 0.36116987179487187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000004)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-24 13:00:00+00:00 Âà∞ 2025-02-27 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15706)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-11 13:00:00+00:00 Âà∞ 2025-03-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step22108 Âπ≥Âùáreward‰∏∫ 0.31764529914529915\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-08 13:00:00+00:00 Âà∞ 2025-03-11 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step22482 Âπ≥Âùáreward‰∏∫ 0.3490491452991457\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-26 13:00:00+00:00 Âà∞ 2024-12-29 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step22880 Âπ≥Âùáreward‰∏∫ 0.41727670940171024\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15706)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-27 13:00:00+00:00 Âà∞ 2024-12-30 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step23275 Âπ≥Âùáreward‰∏∫ 0.3879487179487184\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-02 13:00:00+00:00 Âà∞ 2025-01-05 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step23672 Âπ≥Âùáreward‰∏∫ 0.34640705128205135\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-15 13:00:00+00:00 Âà∞ 2025-02-18 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step24074 Âπ≥Âùáreward‰∏∫ 0.32187927350427353\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-24 13:00:00+00:00 Âà∞ 2025-02-27 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step24472 Âπ≥Âùáreward‰∏∫ 0.3647831196581197\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-04 13:00:00+00:00 Âà∞ 2025-01-07 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-07 13:00:00+00:00 Âà∞ 2025-02-10 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step24873 Âπ≥Âùáreward‰∏∫ 0.3341452991452992\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-06 13:00:00+00:00 Âà∞ 2025-02-09 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step25258 Âπ≥Âùáreward‰∏∫ 0.29105982905982936\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-24 13:00:00+00:00 Âà∞ 2025-02-27 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step25662 Âπ≥Âùáreward‰∏∫ 0.2777767094017095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000005)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-21 13:00:00+00:00 Âà∞ 2025-01-24 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step26065 Âπ≥Âùáreward‰∏∫ 0.27519017094017106\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-10 13:00:00+00:00 Âà∞ 2025-03-13 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step26468 Âπ≥Âùáreward‰∏∫ 0.2418023504273505\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-12 13:00:00+00:00 Âà∞ 2025-01-15 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step26876 Âπ≥Âùáreward‰∏∫ 0.30257478632478646\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-06 13:00:00+00:00 Âà∞ 2025-02-09 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-23 13:00:00+00:00 Âà∞ 2024-12-26 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step27305 Âπ≥Âùáreward‰∏∫ 0.3265160256410258\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-01 13:00:00+00:00 Âà∞ 2025-02-04 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step27700 Âπ≥Âùáreward‰∏∫ 0.3754668803418809\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-12 13:00:00+00:00 Âà∞ 2025-03-15 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step28098 Âπ≥Âùáreward‰∏∫ 0.39886324786324867\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-12 13:00:00+00:00 Âà∞ 2025-02-15 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step28492 Âπ≥Âùáreward‰∏∫ 0.36409722222222257\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-09 13:00:00+00:00 Âà∞ 2025-02-12 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step28888 Âπ≥Âùáreward‰∏∫ 0.31000854700854685\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-03 13:00:00+00:00 Âà∞ 2025-01-06 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step29277 Âπ≥Âùáreward‰∏∫ 0.35647222222222213\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-11 13:00:00+00:00 Âà∞ 2025-03-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15706)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-09 13:00:00+00:00 Âà∞ 2025-01-12 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step29709 Âπ≥Âùáreward‰∏∫ 0.3300117521367524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000006)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-28 13:00:00+00:00 Âà∞ 2024-12-31 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step30081 Âπ≥Âùáreward‰∏∫ 0.3231260683760685\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-10 13:00:00+00:00 Âà∞ 2025-03-13 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step30476 Âπ≥Âùáreward‰∏∫ 0.30969337606837627\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-27 13:00:00+00:00 Âà∞ 2024-12-30 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step30892 Âπ≥Âùáreward‰∏∫ 0.3498963675213678\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-10 13:00:00+00:00 Âà∞ 2025-02-13 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step31291 Âπ≥Âùáreward‰∏∫ 0.3391495726495728\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-07 13:00:00+00:00 Âà∞ 2025-02-10 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step31689 Âπ≥Âùáreward‰∏∫ 0.35121581196581203\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-13 13:00:00+00:00 Âà∞ 2025-01-16 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step32078 Âπ≥Âùáreward‰∏∫ 0.37252991452991463\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-21 13:00:00+00:00 Âà∞ 2025-02-24 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-23 13:00:00+00:00 Âà∞ 2025-01-26 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step32490 Âπ≥Âùáreward‰∏∫ 0.3680299145299148\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-17 13:00:00+00:00 Âà∞ 2025-01-20 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m \n",
      "ü§© step32892 Âπ≥Âùáreward‰∏∫ 0.35038034188034217\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-04 13:00:00+00:00 Âà∞ 2025-03-07 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step33284 Âπ≥Âùáreward‰∏∫ 0.3097564102564104\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-13 13:00:00+00:00 Âà∞ 2025-02-16 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step33675 Âπ≥Âùáreward‰∏∫ 0.301306623931624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000007)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-10 13:00:00+00:00 Âà∞ 2025-02-13 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step34076 Âπ≥Âùáreward‰∏∫ 0.334832264957265\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-07 13:00:00+00:00 Âà∞ 2025-02-10 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step34462 Âπ≥Âùáreward‰∏∫ 0.3423728632478634\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-11 13:00:00+00:00 Âà∞ 2025-01-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-14 13:00:00+00:00 Âà∞ 2025-02-17 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step34883 Âπ≥Âùáreward‰∏∫ 0.3234284188034187\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-07 13:00:00+00:00 Âà∞ 2025-01-10 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step35261 Âπ≥Âùáreward‰∏∫ 0.34972222222222243\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-21 13:00:00+00:00 Âà∞ 2025-02-24 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step35672 Âπ≥Âùáreward‰∏∫ 0.3557371794871799\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15706)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-09 13:00:00+00:00 Âà∞ 2025-02-12 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step36081 Âπ≥Âùáreward‰∏∫ 0.3617051282051285\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-29 13:00:00+00:00 Âà∞ 2025-02-01 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step36480 Âπ≥Âùáreward‰∏∫ 0.377349358974359\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-14 13:00:00+00:00 Âà∞ 2025-02-17 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step36879 Âπ≥Âùáreward‰∏∫ 0.3785811965811966\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-30 13:00:00+00:00 Âà∞ 2025-02-02 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-16 13:00:00+00:00 Âà∞ 2025-01-19 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step37318 Âπ≥Âùáreward‰∏∫ 0.44422970085470115\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-27 13:00:00+00:00 Âà∞ 2025-01-30 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step37687 Âπ≥Âùáreward‰∏∫ 0.439825854700855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000008)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-10 13:00:00+00:00 Âà∞ 2025-03-13 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step38094 Âπ≥Âùáreward‰∏∫ 0.41411431623931694\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-16 13:00:00+00:00 Âà∞ 2025-01-19 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step38507 Âπ≥Âùáreward‰∏∫ 0.3954369658119662\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-11 13:00:00+00:00 Âà∞ 2025-01-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step38912 Âπ≥Âùáreward‰∏∫ 0.4259893162393163\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-10 13:00:00+00:00 Âà∞ 2025-02-13 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step39312 Âπ≥Âùáreward‰∏∫ 0.4513600427350426\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-06 13:00:00+00:00 Âà∞ 2025-01-09 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step39712 Âπ≥Âùáreward‰∏∫ 0.37751068376068364\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-16 13:00:00+00:00 Âà∞ 2025-02-19 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-24 13:00:00+00:00 Âà∞ 2024-12-27 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step40123 Âπ≥Âùáreward‰∏∫ 0.4054818376068376\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-27 13:00:00+00:00 Âà∞ 2025-03-02 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step40515 Âπ≥Âùáreward‰∏∫ 0.4013183760683763\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-09 13:00:00+00:00 Âà∞ 2025-01-12 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step40920 Âπ≥Âùáreward‰∏∫ 0.3934914529914534\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15699)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-21 13:00:00+00:00 Âà∞ 2025-02-24 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step41323 Âπ≥Âùáreward‰∏∫ 0.4400587606837608\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-22 13:00:00+00:00 Âà∞ 2025-02-25 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step41715 Âπ≥Âùáreward‰∏∫ 0.46970619658119656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000009)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-03 13:00:00+00:00 Âà∞ 2025-03-06 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step42116 Âπ≥Âùáreward‰∏∫ 0.4065844017094016\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-29 13:00:00+00:00 Âà∞ 2025-02-01 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15706)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-18 13:00:00+00:00 Âà∞ 2025-02-21 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step42541 Âπ≥Âùáreward‰∏∫ 0.4418290598290599\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-05 13:00:00+00:00 Âà∞ 2025-01-08 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step42911 Âπ≥Âùáreward‰∏∫ 0.44605555555555626\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-22 13:00:00+00:00 Âà∞ 2025-02-25 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step43311 Âπ≥Âùáreward‰∏∫ 0.498444444444446\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15706)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-26 13:00:00+00:00 Âà∞ 2024-12-29 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step43715 Âπ≥Âùáreward‰∏∫ 0.5105822649572656\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-31 13:00:00+00:00 Âà∞ 2025-02-03 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step44111 Âπ≥Âùáreward‰∏∫ 0.4817510683760685\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-26 13:00:00+00:00 Âà∞ 2024-12-29 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step44505 Âπ≥Âùáreward‰∏∫ 0.4431709401709402\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-11 13:00:00+00:00 Âà∞ 2025-01-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step44914 Âπ≥Âùáreward‰∏∫ 0.46854166666666686\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-20 13:00:00+00:00 Âà∞ 2025-02-23 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-11 13:00:00+00:00 Âà∞ 2025-03-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15699)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-28 13:00:00+00:00 Âà∞ 2024-12-31 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step45317 Âπ≥Âùáreward‰∏∫ 0.4880726495726497\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-05 13:00:00+00:00 Âà∞ 2025-03-08 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-31 13:00:00+00:00 Âà∞ 2025-02-03 13:00:00+00:00\n",
      "ü§© step45722 Âπ≥Âùáreward‰∏∫ 0.424675213675214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000010)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-11 13:00:00+00:00 Âà∞ 2025-02-14 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step46120 Âπ≥Âùáreward‰∏∫ 0.4149861111111114\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-11 13:00:00+00:00 Âà∞ 2025-03-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step46519 Âπ≥Âùáreward‰∏∫ 0.4059615384615386\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-04 13:00:00+00:00 Âà∞ 2025-02-07 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step46912 Âπ≥Âùáreward‰∏∫ 0.4422991452991453\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-28 13:00:00+00:00 Âà∞ 2025-01-31 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step47305 Âπ≥Âùáreward‰∏∫ 0.44370833333333337\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-25 13:00:00+00:00 Âà∞ 2024-12-28 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-29 13:00:00+00:00 Âà∞ 2025-02-01 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step47718 Âπ≥Âùáreward‰∏∫ 0.4384252136752138\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-28 13:00:00+00:00 Âà∞ 2025-03-03 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step48104 Âπ≥Âùáreward‰∏∫ 0.4369871794871801\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15706)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-08 13:00:00+00:00 Âà∞ 2025-01-11 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step48496 Âπ≥Âùáreward‰∏∫ 0.45263782051282153\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-24 13:00:00+00:00 Âà∞ 2024-12-27 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step48891 Âπ≥Âùáreward‰∏∫ 0.46948931623931667\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-23 13:00:00+00:00 Âà∞ 2025-01-26 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step49291 Âπ≥Âùáreward‰∏∫ 0.4704561965811967\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-18 13:00:00+00:00 Âà∞ 2025-01-21 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step49686 Âπ≥Âùáreward‰∏∫ 0.4326196581196579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000011)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-26 13:00:00+00:00 Âà∞ 2025-01-29 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-25 13:00:00+00:00 Âà∞ 2024-12-28 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-23 13:00:00+00:00 Âà∞ 2025-01-26 13:00:00+00:00\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "ü§© step50118 Âπ≥Âùáreward‰∏∫ 0.4707980769230773\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-22 13:00:00+00:00 Âà∞ 2024-12-25 13:00:00+00:00\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "ü§© step50488 Âπ≥Âùáreward‰∏∫ 0.47505769230769307\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-10 13:00:00+00:00 Âà∞ 2025-01-13 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step50886 Âπ≥Âùáreward‰∏∫ 0.48575641025641136\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-02 13:00:00+00:00 Âà∞ 2025-01-05 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step51281 Âπ≥Âùáreward‰∏∫ 0.4265416666666673\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-15 13:00:00+00:00 Âà∞ 2025-02-18 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step51680 Âπ≥Âùáreward‰∏∫ 0.4205373931623931\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-05 13:00:00+00:00 Âà∞ 2025-03-08 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step52081 Âπ≥Âùáreward‰∏∫ 0.4455929487179486\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-30 13:00:00+00:00 Âà∞ 2025-01-02 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step52491 Âπ≥Âùáreward‰∏∫ 0.4781987179487179\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-04 13:00:00+00:00 Âà∞ 2025-03-07 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-26 13:00:00+00:00 Âà∞ 2025-01-29 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15699)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-15 13:00:00+00:00 Âà∞ 2025-01-18 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step52903 Âπ≥Âùáreward‰∏∫ 0.4654284188034193\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15699)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-12 13:00:00+00:00 Âà∞ 2025-01-15 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-25 13:00:00+00:00 Âà∞ 2024-12-28 13:00:00+00:00\n",
      "ü§© step53277 Âπ≥Âùáreward‰∏∫ 0.3921517094017096\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15706)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-18 13:00:00+00:00 Âà∞ 2025-01-21 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step53685 Âπ≥Âùáreward‰∏∫ 0.3978408119658122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000012)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-01 13:00:00+00:00 Âà∞ 2025-02-04 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step54088 Âπ≥Âùáreward‰∏∫ 0.3815053418803419\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-21 13:00:00+00:00 Âà∞ 2025-01-24 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step54502 Âπ≥Âùáreward‰∏∫ 0.39318589743589744\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-20 13:00:00+00:00 Âà∞ 2025-01-23 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step54904 Âπ≥Âùáreward‰∏∫ 0.4459423076923076\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-22 13:00:00+00:00 Âà∞ 2024-12-25 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-17 13:00:00+00:00 Âà∞ 2025-02-20 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step55310 Âπ≥Âùáreward‰∏∫ 0.3774658119658121\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-07 13:00:00+00:00 Âà∞ 2025-03-10 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step55700 Âπ≥Âùáreward‰∏∫ 0.3752532051282053\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-10 13:00:00+00:00 Âà∞ 2025-01-13 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step56102 Âπ≥Âùáreward‰∏∫ 0.44757371794871836\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-25 13:00:00+00:00 Âà∞ 2024-12-28 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step56504 Âπ≥Âùáreward‰∏∫ 0.4708824786324789\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-22 13:00:00+00:00 Âà∞ 2025-01-25 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step56902 Âπ≥Âùáreward‰∏∫ 0.36782371794871804\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-11 13:00:00+00:00 Âà∞ 2025-01-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step57292 Âπ≥Âùáreward‰∏∫ 0.4028450854700854\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-04 13:00:00+00:00 Âà∞ 2025-02-07 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-01 13:00:00+00:00 Âà∞ 2025-01-04 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step57711 Âπ≥Âùáreward‰∏∫ 0.41819230769230775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000013)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-16 13:00:00+00:00 Âà∞ 2025-01-19 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-22 13:00:00+00:00 Âà∞ 2024-12-25 13:00:00+00:00\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "ü§© step58089 Âπ≥Âùáreward‰∏∫ 0.44999786324786367\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-01 13:00:00+00:00 Âà∞ 2025-01-04 13:00:00+00:00\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "ü§© step58490 Âπ≥Âùáreward‰∏∫ 0.4918525641025649\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-08 13:00:00+00:00 Âà∞ 2025-02-11 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step58895 Âπ≥Âùáreward‰∏∫ 0.4723247863247865\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-27 13:00:00+00:00 Âà∞ 2025-01-30 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step59428 Âπ≥Âùáreward‰∏∫ 0.44778846153846136\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-24 13:00:00+00:00 Âà∞ 2025-01-27 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step59871 Âπ≥Âùáreward‰∏∫ 0.44965277777777773\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-29 13:00:00+00:00 Âà∞ 2025-02-01 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step60289 Âπ≥Âùáreward‰∏∫ 0.45634081196581183\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-07 13:00:00+00:00 Âà∞ 2025-02-10 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-11 13:00:00+00:00 Âà∞ 2025-02-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-01 13:00:00+00:00 Âà∞ 2025-02-04 13:00:00+00:00\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "ü§© step60716 Âπ≥Âùáreward‰∏∫ 0.452192307692308\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-16 13:00:00+00:00 Âà∞ 2025-02-19 13:00:00+00:00\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "ü§© step61128 Âπ≥Âùáreward‰∏∫ 0.560707264957266\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-25 13:00:00+00:00 Âà∞ 2025-01-28 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step61557 Âπ≥Âùáreward‰∏∫ 0.5461356837606844\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-05 13:00:00+00:00 Âà∞ 2025-01-08 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step61974 Âπ≥Âùáreward‰∏∫ 0.4833418803418805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000014)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-12 13:00:00+00:00 Âà∞ 2025-01-15 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step62395 Âπ≥Âùáreward‰∏∫ 0.4466132478632479\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-18 13:00:00+00:00 Âà∞ 2025-01-21 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step62809 Âπ≥Âùáreward‰∏∫ 0.4007403846153845\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-27 13:00:00+00:00 Âà∞ 2024-12-30 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-19 13:00:00+00:00 Âà∞ 2025-01-22 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step63252 Âπ≥Âùáreward‰∏∫ 0.537966880341881\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-12 13:00:00+00:00 Âà∞ 2025-01-15 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step63643 Âπ≥Âùáreward‰∏∫ 0.47778098290598364\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-28 13:00:00+00:00 Âà∞ 2025-03-03 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step64060 Âπ≥Âùáreward‰∏∫ 0.45817735042735097\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-27 13:00:00+00:00 Âà∞ 2025-03-02 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step64484 Âπ≥Âùáreward‰∏∫ 0.5415608974358977\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-14 13:00:00+00:00 Âà∞ 2025-01-17 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step64899 Âπ≥Âùáreward‰∏∫ 0.5778856837606838\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15706)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-02 13:00:00+00:00 Âà∞ 2025-03-05 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step65333 Âπ≥Âùáreward‰∏∫ 0.5174017094017095\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-04 13:00:00+00:00 Âà∞ 2025-02-07 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-09 13:00:00+00:00 Âà∞ 2025-03-12 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step65792 Âπ≥Âùáreward‰∏∫ 0.552677350427351\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-14 13:00:00+00:00 Âà∞ 2025-01-17 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step66190 Âπ≥Âùáreward‰∏∫ 0.5770202991453002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000015)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-03 13:00:00+00:00 Âà∞ 2025-02-06 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step66617 Âπ≥Âùáreward‰∏∫ 0.5567628205128218\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-23 13:00:00+00:00 Âà∞ 2025-01-26 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step67033 Âπ≥Âùáreward‰∏∫ 0.5505705128205137\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-01 13:00:00+00:00 Âà∞ 2025-01-04 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step67439 Âπ≥Âùáreward‰∏∫ 0.5425405982905984\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-03 13:00:00+00:00 Âà∞ 2025-03-06 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step67857 Âπ≥Âùáreward‰∏∫ 0.5016826923076924\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-15 13:00:00+00:00 Âà∞ 2025-02-18 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step68279 Âπ≥Âùáreward‰∏∫ 0.41987286324786327\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-06 13:00:00+00:00 Âà∞ 2025-02-09 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-22 13:00:00+00:00 Âà∞ 2025-01-25 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15699)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-11 13:00:00+00:00 Âà∞ 2025-03-14 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step68714 Âπ≥Âùáreward‰∏∫ 0.5025181623931627\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-16 13:00:00+00:00 Âà∞ 2025-02-19 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-28 13:00:00+00:00 Âà∞ 2025-03-03 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-05 13:00:00+00:00 Âà∞ 2025-01-08 13:00:00+00:00\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "ü§© step69120 Âπ≥Âùáreward‰∏∫ 0.44054807692307746\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-30 13:00:00+00:00 Âà∞ 2025-02-02 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-24 13:00:00+00:00 Âà∞ 2024-12-27 13:00:00+00:00\n",
      "ü§© step69529 Âπ≥Âùáreward‰∏∫ 0.46870940170940234\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-05 13:00:00+00:00 Âà∞ 2025-01-08 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step69964 Âπ≥Âùáreward‰∏∫ 0.4810085470085472\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-25 13:00:00+00:00 Âà∞ 2025-02-28 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step70382 Âπ≥Âùáreward‰∏∫ 0.5065096153846153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000016)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-23 13:00:00+00:00 Âà∞ 2025-02-26 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step70808 Âπ≥Âùáreward‰∏∫ 0.42400320512820505\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-27 13:00:00+00:00 Âà∞ 2025-01-30 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-28 13:00:00+00:00 Âà∞ 2024-12-31 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-06 13:00:00+00:00 Âà∞ 2025-03-09 13:00:00+00:00\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "ü§© step71264 Âπ≥Âùáreward‰∏∫ 0.4612222222222223\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-20 13:00:00+00:00 Âà∞ 2025-01-23 13:00:00+00:00\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-06 13:00:00+00:00 Âà∞ 2025-03-09 13:00:00+00:00\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "ü§© step71663 Âπ≥Âùáreward‰∏∫ 0.4697115384615393\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-11 13:00:00+00:00 Âà∞ 2025-02-14 13:00:00+00:00\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "ü§© step72089 Âπ≥Âùáreward‰∏∫ 0.5013301282051292\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-11 13:00:00+00:00 Âà∞ 2025-02-14 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step72502 Âπ≥Âùáreward‰∏∫ 0.525924145299146\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-04 13:00:00+00:00 Âà∞ 2025-01-07 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step72920 Âπ≥Âùáreward‰∏∫ 0.46662393162393195\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-02 13:00:00+00:00 Âà∞ 2025-03-05 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step73324 Âπ≥Âùáreward‰∏∫ 0.4947820512820512\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-27 13:00:00+00:00 Âà∞ 2025-01-30 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-12 13:00:00+00:00 Âà∞ 2025-02-15 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-06 13:00:00+00:00 Âà∞ 2025-03-09 13:00:00+00:00\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "ü§© step73775 Âπ≥Âùáreward‰∏∫ 0.4028814102564104\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-22 13:00:00+00:00 Âà∞ 2024-12-25 13:00:00+00:00\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "ü§© step74156 Âπ≥Âùáreward‰∏∫ 0.4502916666666673\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-26 13:00:00+00:00 Âà∞ 2024-12-29 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-15 13:00:00+00:00 Âà∞ 2025-01-18 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step74573 Âπ≥Âùáreward‰∏∫ 0.4511495726495734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000017)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-25 13:00:00+00:00 Âà∞ 2025-02-28 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-24 13:00:00+00:00 Âà∞ 2025-01-27 13:00:00+00:00\n",
      "ü§© step74996 Âπ≥Âùáreward‰∏∫ 0.5079540598290604\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-10 13:00:00+00:00 Âà∞ 2025-03-13 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step75446 Âπ≥Âùáreward‰∏∫ 0.5215277777777781\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-18 13:00:00+00:00 Âà∞ 2025-02-21 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step75910 Âπ≥Âùáreward‰∏∫ 0.5431891025641026\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-28 13:00:00+00:00 Âà∞ 2024-12-31 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step76352 Âπ≥Âùáreward‰∏∫ 0.5498173076923076\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-13 13:00:00+00:00 Âà∞ 2025-01-16 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-25 13:00:00+00:00 Âà∞ 2025-02-28 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-06 13:00:00+00:00 Âà∞ 2025-01-09 13:00:00+00:00\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "ü§© step76788 Âπ≥Âùáreward‰∏∫ 0.4671442307692312\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-31 13:00:00+00:00 Âà∞ 2025-01-03 13:00:00+00:00\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-09 13:00:00+00:00 Âà∞ 2025-02-12 13:00:00+00:00\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "ü§© step77212 Âπ≥Âùáreward‰∏∫ 0.41930235042735087\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-03 13:00:00+00:00 Âà∞ 2025-02-06 13:00:00+00:00\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-18 13:00:00+00:00 Âà∞ 2025-01-21 13:00:00+00:00\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "ü§© step77638 Âπ≥Âùáreward‰∏∫ 0.48303418803418885\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-03 13:00:00+00:00 Âà∞ 2025-02-06 13:00:00+00:00\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "ü§© step78049 Âπ≥Âùáreward‰∏∫ 0.5457873931623938\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-02 13:00:00+00:00 Âà∞ 2025-01-05 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step78467 Âπ≥Âùáreward‰∏∫ 0.5214604700854701\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-04 13:00:00+00:00 Âà∞ 2025-03-07 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step78879 Âπ≥Âùáreward‰∏∫ 0.557667735042735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000018)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-08 13:00:00+00:00 Âà∞ 2025-03-11 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-30 13:00:00+00:00 Âà∞ 2025-02-02 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-19 13:00:00+00:00 Âà∞ 2025-02-22 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step79322 Âπ≥Âùáreward‰∏∫ 0.5829027777777787\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-07 13:00:00+00:00 Âà∞ 2025-01-10 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-27 13:00:00+00:00 Âà∞ 2024-12-30 13:00:00+00:00\n",
      "ü§© step79724 Âπ≥Âùáreward‰∏∫ 0.5370395299145309\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-17 13:00:00+00:00 Âà∞ 2025-02-20 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15693)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-25 13:00:00+00:00 Âà∞ 2025-02-28 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step80156 Âπ≥Âùáreward‰∏∫ 0.4984155982905991\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-23 13:00:00+00:00 Âà∞ 2025-01-26 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15698)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-12 13:00:00+00:00 Âà∞ 2025-01-15 13:00:00+00:00\n",
      "ü§© step80584 Âπ≥Âùáreward‰∏∫ 0.5714893162393166\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2024-12-29 13:00:00+00:00 Âà∞ 2025-01-01 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step81003 Âπ≥Âùáreward‰∏∫ 0.5097286324786325\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-14 13:00:00+00:00 Âà∞ 2025-02-17 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step81404 Âπ≥Âùáreward‰∏∫ 0.46549572649572646\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-14 13:00:00+00:00 Âà∞ 2025-02-17 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-06 13:00:00+00:00 Âà∞ 2025-01-09 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-04 13:00:00+00:00 Âà∞ 2025-02-07 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step81860 Âπ≥Âùáreward‰∏∫ 0.5420576923076929\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15696)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-16 13:00:00+00:00 Âà∞ 2025-01-19 13:00:00+00:00\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15694)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-01-18 13:00:00+00:00 Âà∞ 2025-01-21 13:00:00+00:00\n",
      "ü§© step82251 Âπ≥Âùáreward‰∏∫ 0.5054529914529919\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-03-02 13:00:00+00:00 Âà∞ 2025-03-05 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "ü§© step82675 Âπ≥Âùáreward‰∏∫ 0.4683803418803421\n",
      "\u001b[36m(SingleAgentEnvRunner pid=15697)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-14 13:00:00+00:00 Âà∞ 2025-02-17 13:00:00+00:00\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "ü§© step83097 Âπ≥Âùáreward‰∏∫ 0.4654903846153849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(PPO(env=<class '__main__.WorkerScaling'>; env-runners=8; learners=0; multi-agent=False) pid=15632)\u001b[0m Checkpoint successfully created at: Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000019)\n",
      "2025-06-26 05:04:39,899\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/home/ypp/ray_results/PPO_2025-06-26_02-43-11' in 0.1433s.\n",
      "2025-06-26 05:04:40,239\tINFO tune.py:1041 -- Total run time: 8488.33 seconds (8487.71 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(SingleAgentEnvRunner pid=15695)\u001b[0m ‚úÖ ÈÄâ‰∏≠ÁöÑÊó∂Èó¥ÊÆµÔºö2025-02-11 13:00:00+00:00 Âà∞ 2025-02-14 13:00:00+00:00\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "Best result: Result(\n",
      "  metrics={'timers': {'training_iteration': 42.70518487694511, 'restore_env_runners': 4.407265012087706e-05, 'training_step': 42.704281871117566, 'env_runner_sampling_timer': 28.472219710304763, 'learner_update_timer': 14.219490902018416, 'synch_weights': 0.010916667453998026, 'synch_env_connectors': 0.013966295704162671}, 'env_runners': {'episode_return_min': 0.2627777777777777, 'module_to_env_connector': {'timers': {'connectors': {'remove_single_ts_time_rank_from_batch': np.float64(1.2484567710691035e-05), 'get_actions': np.float64(0.0010395520389616141), 'un_batch_to_individual_items': np.float64(0.00010400964541281775), 'tensor_to_numpy': np.float64(0.0003316935901084214), 'listify_data_for_vector_env': np.float64(0.00019797636640048923), 'normalize_and_clip_actions': np.float64(0.00016861652724151264)}}, 'connector_pipeline_timer': np.float64(0.0023264949618258136)}, 'num_episodes_lifetime': 1848, 'env_to_module_connector': {'timers': {'connectors': {'batch_individual_items': np.float64(0.00014173326620110392), 'add_states_from_episodes_to_batch': np.float64(2.9620088335786173e-05), 'numpy_to_tensor': np.float64(0.00023094151539839982), 'add_time_dim_to_batch_and_zero_pad': np.float64(4.977403328423932e-05), 'add_observations_from_episodes_to_batch': np.float64(5.456656158560829e-05)}}, 'connector_pipeline_timer': np.float64(0.0008697904591026213)}, 'episode_return_mean': 0.4654903846153849, 'num_module_steps_sampled': {'default_policy': 2000}, 'episode_len_min': 216, 'num_module_steps_sampled_lifetime': {'default_policy': 400000}, 'episode_return_max': 0.6788888888888903, 'env_step_timer': np.float64(0.09866154293952545), 'env_to_module_sum_episodes_length_out': np.float64(93.80785496779632), 'num_env_steps_sampled': 2000, 'sample': np.float64(26.775864138154944), 'episode_len_max': 216, 'env_reset_timer': np.float64(4.086234589500236), 'num_agent_steps_sampled': {'default_agent': 2000}, 'num_agent_steps_sampled_lifetime': {'default_agent': 400000}, 'episode_duration_sec_mean': 19.739570516201567, 'module_episode_returns_mean': {'default_policy': 0.4654903846153849}, 'rlmodule_inference_timer': np.float64(0.000801781817147362), 'num_env_steps_sampled_lifetime': 400000, 'num_episodes': 8, 'agent_episode_returns_mean': {'default_agent': 0.4654903846153849}, 'episode_len_mean': 216.0, 'weights_seq_no': 199.0, 'env_to_module_sum_episodes_length_in': np.float64(93.80785496779632), 'time_between_sampling': np.float64(16.035366306382283), 'num_env_steps_sampled_lifetime_throughput': 46.09064447532183}, 'learners': {'__all_modules__': {'learner_connector_sum_episodes_length_out': 2016.713326666458, 'learner_connector': {'timers': {'connectors': {'add_time_dim_to_batch_and_zero_pad': 6.042930834671405e-05, 'add_columns_from_episodes_to_train_batch': 0.15351716896353948, 'add_observations_from_episodes_to_batch': 0.0007016455922639428, 'add_one_ts_to_episodes_and_truncate': 0.011680853215531299, 'batch_individual_items': 0.08953169527979005, 'general_advantage_estimation': 0.11234784374764584, 'add_states_from_episodes_to_batch': 2.0264874019747135e-05, 'numpy_to_tensor': 0.0019945028075147517}}, 'connector_pipeline_timer': 0.37065784284398284}, 'num_env_steps_trained_lifetime': 190948560, 'num_trainable_parameters': 75527.0, 'num_env_steps_trained': 953568, 'num_module_steps_trained': 60544, 'learner_connector_sum_episodes_length_in': 2000.0, 'num_non_trainable_parameters': 0.0, 'num_module_steps_trained_lifetime': 12116480, 'num_env_steps_trained_lifetime_throughput': 0.0}, 'default_policy': {'num_module_steps_trained_lifetime': 12116480, 'diff_num_grad_updates_vs_sampler_policy': np.float32(1.0), 'weights_seq_no': 200.0, 'vf_loss': np.float32(0.0025301585), 'curr_kl_coeff': 0.5406097769737244, 'curr_entropy_coeff': 0.0, 'module_train_batch_size_mean': 128.0, 'policy_loss': np.float32(-0.14330462), 'default_optimizer_learning_rate': 0.0003, 'total_loss': np.float32(-0.1362771), 'num_trainable_parameters': 75527.0, 'entropy': np.float32(0.3078108), 'vf_explained_var': np.float32(0.38390273), 'mean_kl_loss': np.float32(0.008319024), 'num_module_steps_trained': 60544, 'vf_loss_unclipped': np.float32(0.0025301585), 'gradients_default_optimizer_global_norm': np.float32(1.9911885)}}, 'num_training_step_calls_per_iteration': 1, 'num_env_steps_sampled_lifetime': 400000, 'fault_tolerance': {'num_healthy_workers': 8, 'num_remote_worker_restarts': 0}, 'env_runner_group': {'actor_manager_num_outstanding_async_reqs': 0}, 'num_env_steps_sampled_lifetime_throughput': 46.09064447532183, 'perf': {'cpu_util_percent': np.float64(69.7573770491803), 'ram_util_percent': np.float64(57.954098360655735)}},\n",
      "  path='/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12',\n",
      "  filesystem='local',\n",
      "  checkpoint=Checkpoint(filesystem=local, path=/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000019)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from ray.tune import Callback\n",
    "from ray.rllib.utils.test_utils import (\n",
    "    add_rllib_example_script_args,\n",
    "    run_rllib_example_script_experiment,\n",
    ")\n",
    "from ray.rllib.utils.metrics import (\n",
    "    ENV_RUNNER_RESULTS,\n",
    "    EPISODE_RETURN_MEAN,\n",
    ")\n",
    "from ray.rllib.core.rl_module.rl_module import RLModuleSpec\n",
    "from ray.rllib.core.rl_module.default_model_config import DefaultModelConfig\n",
    "from ray.rllib.algorithms.ppo.torch.default_ppo_torch_rl_module import DefaultPPOTorchRLModule\n",
    "from ray.rllib.algorithms.ppo import PPOConfig\n",
    "\n",
    "import lib.model.transformer as transformer\n",
    "\n",
    "parser = add_rllib_example_script_args(\n",
    "    default_reward=1.5, default_iters=200, default_timesteps=1000000\n",
    ")\n",
    "parser.set_defaults(\n",
    "    # Make sure that - by default - we produce checkpoints during training.\n",
    "    checkpoint_freq=10,\n",
    "    checkpoint_at_end=True,\n",
    "    # Script only runs on new API stack.\n",
    "    enable_new_api_stack=True,\n",
    ")\n",
    "args = parser.parse_args([])\n",
    "\n",
    "iter_setps, episode_reward = [], []\n",
    "class TuneCallback(Callback):\n",
    "    def on_trial_result(self, iteration, trials, trial, result,\n",
    "                        **info):\n",
    "        if result.get(ENV_RUNNER_RESULTS) and result.get(ENV_RUNNER_RESULTS).get(EPISODE_RETURN_MEAN):\n",
    "            print(f\"ü§© step{iteration} Âπ≥Âùáreward‰∏∫ {result[ENV_RUNNER_RESULTS][EPISODE_RETURN_MEAN]}\")\n",
    "            iter_setps.append(iteration)\n",
    "            episode_reward.append(result[ENV_RUNNER_RESULTS][EPISODE_RETURN_MEAN])\n",
    "\n",
    "base_config = (\n",
    "        PPOConfig()\n",
    "        .api_stack(\n",
    "            enable_rl_module_and_learner=True,\n",
    "            enable_env_runner_and_connector_v2=True,\n",
    "        )\n",
    "        .rl_module(\n",
    "            model_config=DefaultModelConfig(\n",
    "                # fcnet_hiddens=[128, 128],\n",
    "                fcnet_activation=\"relu\",\n",
    "                # head_fcnet_hiddens=[32, 32],\n",
    "                vf_share_layers=True,\n",
    "            )\n",
    "        )\n",
    "        # .rl_module(\n",
    "        #     rl_module_spec=RLModuleSpec(\n",
    "        #         module_class=DefaultPPOTorchRLModule,\n",
    "        #         catalog_class=transformer.TransformerEncoderCatalog,\n",
    "        #         model_config={\n",
    "        #             \"head_fcnet_hiddens\": [128,128],\n",
    "        #             \"head_fcnet_activation\": \"relu\",\n",
    "        #             \"vf_share_layers\": True,\n",
    "        #             \"d_model\": 128,\n",
    "        #             \"n_layer\": 2,\n",
    "        #             \"embedding_dropout\": 0,\n",
    "        #             \"embedding_bias\": False,\n",
    "        #             \"embedding_position_type\": \"\",\n",
    "        #         },\n",
    "        #     ),\n",
    "        # )\n",
    "        .env_runners(num_env_runners=8, num_gpus_per_env_runner=0, num_cpus_per_env_runner=0.1)\n",
    "        .learners(num_gpus_per_learner=1, num_cpus_per_learner=1)\n",
    "        .training(\n",
    "            train_batch_size_per_learner = 2000,\n",
    "            lambda_ = 0.97,\n",
    "            vf_loss_coeff = 1,\n",
    "            kl_coeff = 0.2,\n",
    "            lr = 3e-4\n",
    "        )\n",
    "        .environment(\n",
    "            WorkerScaling,\n",
    "            env_config={\"observe_length\": observe_length, \"future_length\": future_length}\n",
    "        )\n",
    "\n",
    "    )\n",
    "\n",
    "results = run_rllib_example_script_experiment(base_config, args, tune_callbacks=[TuneCallback()])\n",
    "\n",
    "best_result = results.get_best_result(\n",
    "    metric=f\"{ENV_RUNNER_RESULTS}/{EPISODE_RETURN_MEAN}\", mode=\"max\"\n",
    ")\n",
    "print(f\"Best result: {best_result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "877b4a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ RLlib ËÆ≠ÁªÉÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞ rl/tmp/rllib_results.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Plot the reward per iteration\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(iter_setps, episode_reward, label='Reward per step')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Reward')\n",
    "plt.title('Reward per step')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "# Save the results to a CSV file\n",
    "output_csv_path = os.path.join('rl/tmp', 'rllib_results.csv')\n",
    "os.makedirs('rl/tmp', exist_ok=True)\n",
    "with open(output_csv_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['step', 'reward']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for step, reward in zip(iter_setps, episode_reward):\n",
    "        writer.writerow({'step': step, 'reward': reward})\n",
    "print(f\"‚úÖ RLlib ËÆ≠ÁªÉÁªìÊûúÂ∑≤‰øùÂ≠òÂà∞ {output_csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e467c7",
   "metadata": {},
   "source": [
    "### Test evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "65cd38b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu or mps\n",
      "Use CPU\n",
      "ü§© ÊÄªreward‰∏∫Ôºö 0.5245555555555554\n",
      "‚úÖ ÁîüÊàêÁöÑÊåáÊ†áÊï∞ÊçÆÂ∑≤‰øùÂ≠òÂà∞ rl/tmp/metrics.csv\n"
     ]
    }
   ],
   "source": [
    "from ray.rllib.core import DEFAULT_MODULE_ID\n",
    "from ray.rllib.core.columns import Columns\n",
    "from ray.rllib.core.rl_module.rl_module import RLModule\n",
    "from ray.rllib.utils.numpy import convert_to_numpy, softmax\n",
    "\n",
    "rl_module = RLModule.from_checkpoint(\n",
    "    os.path.join(\n",
    "        '/home/ypp/ray_results/PPO_2025-06-26_02-43-11/PPO_WorkerScaling_3efe5_00000_0_2025-06-26_02-43-12/checkpoint_000015',\n",
    "        \"learner_group\",\n",
    "        \"learner\",\n",
    "        \"rl_module\",\n",
    "        DEFAULT_MODULE_ID,\n",
    "    )\n",
    ")\n",
    "\n",
    "tasks, base_time = load_tasks_from_csv('rl/tmp')\n",
    "env = WorkerScaling(config={\"observe_length\": observe_length, \"future_length\": future_length,})\n",
    "env.init_simulator(tasks, base_time)\n",
    "simulator = env.simulator\n",
    "\n",
    "action = init_workers - min_workers\n",
    "while True:\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    if terminated or truncated:\n",
    "        break\n",
    "    input_dict = {Columns.OBS: torch.from_numpy(obs).unsqueeze(0)}\n",
    "    rl_module_out = rl_module.forward_inference(input_dict)\n",
    "    logits = convert_to_numpy(rl_module_out[Columns.ACTION_DIST_INPUTS])\n",
    "    # get action with the largest probability\n",
    "    action = np.argmax(logits[0])\n",
    "\n",
    "print(\"ü§© ÊÄªreward‰∏∫Ôºö\", sum([m.reward for m in simulator.metrics]))\n",
    "simulator.plot_metrics(\"rl/tmp\")\n",
    "save_metrics_to_csv(simulator.metrics, 'rl/tmp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
