{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1097c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a66f1",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653ab51b",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.10.6' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages.\n",
      "\u001b[1;31mOr install 'ipykernel' using the command: '\"d:/Program Files/Python/python.exe\" -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "# 下载 metadata.parquet 文件\n",
    "table_url = 'https://huggingface.co/datasets/poloclub/diffusiondb/resolve/main/metadata.parquet'\n",
    "urlretrieve(table_url, 'metadata.parquet')\n",
    "\n",
    "# 读取 parquet 文件\n",
    "metadata_df = pd.read_parquet('metadata.parquet')\n",
    "\n",
    "# 选择需要的列\n",
    "columns_to_keep = ['prompt', 'step', 'cfg', 'sampler', 'width', 'height']\n",
    "filtered_df = metadata_df[columns_to_keep]\n",
    "\n",
    "# 使用 iloc 选择第 20,000 至第 79,999 行数据\n",
    "subset_df = filtered_df.iloc[20000:80000]\n",
    "\n",
    "# 将数据保存为 CSV 文件\n",
    "subset_df.to_csv('../data/diffusiondb_metadata_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d71baee",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2facfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# 加载预训练的分词器，例如使用 BERT 的分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('../data/diffusiondb_metadata_subset.csv')\n",
    "\n",
    "# 定义一个函数，计算文本的 token 数量\n",
    "def count_tokens(text):\n",
    "    # 使用分词器将文本编码为 token ID，并获取 token 数量\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)\n",
    "    return len(tokens)\n",
    "\n",
    "df['prompt'] = df['prompt'].astype(str)\n",
    "# 应用该函数到 'prompt' 列，创建一个新的 'token_count' 列\n",
    "df['token_count'] = df['prompt'].apply(count_tokens)\n",
    "\n",
    "# 过滤 'cfg' 列大于 20 且 'width' 和 'height' 列之积大于 2500 的行\n",
    "df = df[(df['cfg'] >= 0)  & (df['cfg'] <= 20) & (df['width'] < 2500) & (df['height'] < 2500)]\n",
    "\n",
    "# 计算 'step' 列的最小值和最大值\n",
    "min_step = df['step'].min()\n",
    "max_step = df['step'].max()\n",
    "\n",
    "# 定义一个函数，将 'step' 值映射到新的范围\n",
    "def scale_step(value):\n",
    "    if value < 50:\n",
    "        return int((value - min_step) / (50 - min_step) * 20)\n",
    "    else:\n",
    "        return int((value - 50) / (max_step - 50) * (50 - 20) + 20)\n",
    "\n",
    "# 使用 apply 方法应用 scale_step 函数，并将结果赋值回 'step' 列\n",
    "df['step'] = df['step'].apply(scale_step)\n",
    "\n",
    "# 过滤掉 'step' 列值为 0 的行\n",
    "df = df[df['step'] != 0]\n",
    "\n",
    "df.insert(0, 'id', range(1, len(df) + 1))\n",
    "\n",
    "# 保存结果到新的 CSV 文件\n",
    "df.to_csv('../data/all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22ff3e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv('../data/all.csv')\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "val1_df, train_df = train_test_split(train_df, test_size=0.99, random_state=42)\n",
    "val10_df, train_df = train_test_split(train_df, test_size=0.9, random_state=42)  \n",
    "\n",
    "train_df.to_csv('../data/train.csv', index=False)\n",
    "val1_df.to_csv('../data/train_mini.csv', index=False)\n",
    "val10_df.to_csv('../data/train_small.csv', index=False)\n",
    "test_df.to_csv('../data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4ea93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = '../data/train_mini.csv'\n",
    "output_file = '../experiment/input/test1.csv'\n",
    "\n",
    "with open(input_file, mode='r', newline='') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    rows = list(reader)\n",
    "\n",
    "\n",
    "header = rows[0] + ['timestamp']\n",
    "# 添加 timestamp 为 0 的数据到每一行\n",
    "for row in rows[1:]:\n",
    "    row.append(0)\n",
    "\n",
    "with open(output_file, mode='w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerow(header)\n",
    "    writer.writerows(rows[1:])\n",
    "\n",
    "print(f\"Updated CSV file saved as {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6909c6",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078863ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# 读取 CSV 文件，确保第一行作为列名\n",
    "df = pd.read_csv('../data/all.csv')\n",
    "\n",
    "# 将 'cfg' 列转换为浮点数类型，处理可能的转换错误\n",
    "df['cfg'] = df['cfg'].astype(float)\n",
    "\n",
    "# 设置绘图风格\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# 创建子图\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "\n",
    "# 变量列表\n",
    "variables = ['step', 'cfg', 'sampler', 'width', 'height', 'token_count']\n",
    "\n",
    "# 绘制每个变量的直方图\n",
    "for i, var in enumerate(variables):\n",
    "    ax = axes[i // 3, i % 3]\n",
    "    n, bins, patches = ax.hist(df[var], bins=10, color='skyblue', edgecolor='black')\n",
    "    ax.set_title(f'{var.capitalize()} Distribution')\n",
    "    ax.set_xlabel(var.capitalize())\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "    # 在每个 bin 上方添加数量标签\n",
    "    for patch, count in zip(patches, n):\n",
    "        height = patch.get_height()\n",
    "        ax.annotate(f'{int(count)}', xy=(patch.get_x() + patch.get_width() / 2, height),\n",
    "                    xytext=(0, 5), textcoords='offset points',\n",
    "                    ha='center', va='bottom', fontsize=9)\n",
    "    \n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
