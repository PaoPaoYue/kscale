{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaadd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../external/tslib')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f18c22e",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5365dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入CSV\n",
    "df = pd.read_csv('../data/request_timeseries_all.csv')\n",
    "\n",
    "# 把 timestamp 转成 date\n",
    "df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "\n",
    "# 删除原来的 timestamp\n",
    "df = df.drop(columns=['timestamp'])\n",
    "\n",
    "# 把 date 列放到最前面\n",
    "df = df[['date', 'requests']]\n",
    "\n",
    "# roll up evry 10 data points\n",
    "group_size = 10\n",
    "grouped = df.groupby(df.index // group_size)\n",
    "\n",
    "# 构建结果 DataFrame：保留起始时间，计算归一化请求数\n",
    "result = grouped.agg({\n",
    "    \"date\": \"first\",\n",
    "    \"requests\": lambda x: x.sum() / 120\n",
    "})\n",
    "\n",
    "result.to_csv('../data/request_timeseries_aggregated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df31d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集，将数据集分为训练集和测试集，后30%作为测试集\n",
    "\n",
    "df = pd.read_csv('../data/request_timeseries_all.csv')\n",
    "train_size = int(len(df) * 0.7)\n",
    "train_data = df[:train_size]\n",
    "test_data = df[train_size:]\n",
    "train_data.to_csv('../data/request_timeseries_train.csv', index=False)\n",
    "test_data.to_csv('../data/request_timeseries_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91dcbd7",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6e95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内部用前70%作为训练集\n",
    "from lib.forecast.tslib_util import (\n",
    "    parse_tslib_args,\n",
    "    run_rslib_training,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_TimesNet_custom_ftS_sl36_ll18_pl36_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 5912\n",
      "val 821\n",
      "test 1674\n",
      "\titers: 100, epoch: 1 | loss: 0.8006218\n",
      "\tspeed: 0.1288s/iter; left time: 273.2552s\n",
      "Epoch: 1 cost time: 23.77434515953064\n",
      "Epoch: 1, Steps: 185 | Train Loss: 1.0592931 Vali Loss: 0.5712931 Test Loss: 1.1151127\n",
      "Validation loss decreased (inf --> 0.571293).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3163972\n",
      "\tspeed: 0.2978s/iter; left time: 576.4578s\n",
      "Epoch: 2 cost time: 25.94798994064331\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.4102752 Vali Loss: 0.3802178 Test Loss: 0.8637551\n",
      "Validation loss decreased (0.571293 --> 0.380218).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2887527\n",
      "\tspeed: 0.3616s/iter; left time: 633.2391s\n",
      "Epoch: 3 cost time: 28.733076333999634\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.3378826 Vali Loss: 0.3086973 Test Loss: 0.7760668\n",
      "Validation loss decreased (0.380218 --> 0.308697).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2726199\n",
      "\tspeed: 0.3677s/iter; left time: 575.7461s\n",
      "Epoch: 4 cost time: 29.238857984542847\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.3157589 Vali Loss: 0.3052399 Test Loss: 0.7640244\n",
      "Validation loss decreased (0.308697 --> 0.305240).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3585177\n",
      "\tspeed: 0.3181s/iter; left time: 439.3442s\n",
      "Epoch: 5 cost time: 26.237217903137207\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.3047147 Vali Loss: 0.2965307 Test Loss: 0.7573614\n",
      "Validation loss decreased (0.305240 --> 0.296531).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3319466\n",
      "\tspeed: 0.3176s/iter; left time: 379.8619s\n",
      "Epoch: 6 cost time: 26.400001287460327\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.3018558 Vali Loss: 0.2966532 Test Loss: 0.7586580\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2978745\n",
      "\tspeed: 0.3129s/iter; left time: 316.3717s\n",
      "Epoch: 7 cost time: 24.153799533843994\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.2975555 Vali Loss: 0.2961156 Test Loss: 0.7560703\n",
      "Validation loss decreased (0.296531 --> 0.296116).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2877584\n",
      "\tspeed: 0.3187s/iter; left time: 263.2318s\n",
      "Epoch: 8 cost time: 25.267022609710693\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.2970241 Vali Loss: 0.2944092 Test Loss: 0.7555751\n",
      "Validation loss decreased (0.296116 --> 0.294409).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.3538359\n",
      "\tspeed: 0.2992s/iter; left time: 191.8006s\n",
      "Epoch: 9 cost time: 25.252542734146118\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.2975125 Vali Loss: 0.2945339 Test Loss: 0.7565024\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1929944\n",
      "\tspeed: 0.3078s/iter; left time: 140.3529s\n",
      "Epoch: 10 cost time: 25.51483726501465\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.2961538 Vali Loss: 0.2944342 Test Loss: 0.7569045\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.2315100\n",
      "\tspeed: 0.2993s/iter; left time: 81.0968s\n",
      "Epoch: 11 cost time: 23.21797466278076\n",
      "Epoch: 11, Steps: 185 | Train Loss: 0.2997264 Vali Loss: 0.2962295 Test Loss: 0.7566645\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_TimesNet_custom_ftS_sl36_ll18_pl36_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1674\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "mse:0.7633064985275269, mae:0.5624377131462097, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'TimesNet',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--d_model', '16',\n",
    "        '--d_ff', '32',\n",
    "        '--des', 'Exp',\n",
    "        '--itr', '1',\n",
    "        '--top_k', '5',\n",
    "        '--train_epochs', '12',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_rslib_training(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8479c503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_Transformer_custom_ftS_sl36_ll18_pl36_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 5912\n",
      "val 821\n",
      "test 1674\n",
      "\titers: 100, epoch: 1 | loss: 1.1000764\n",
      "\tspeed: 0.0419s/iter; left time: 88.7785s\n",
      "Epoch: 1 cost time: 6.521451950073242\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.9944567 Vali Loss: 0.9976652 Test Loss: 1.5601455\n",
      "Validation loss decreased (inf --> 0.997665).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8269493\n",
      "\tspeed: 0.0728s/iter; left time: 141.0362s\n",
      "Epoch: 2 cost time: 6.203496932983398\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.7940845 Vali Loss: 0.8185077 Test Loss: 1.2571694\n",
      "Validation loss decreased (0.997665 --> 0.818508).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6932233\n",
      "\tspeed: 0.0759s/iter; left time: 132.9599s\n",
      "Epoch: 3 cost time: 5.880542516708374\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.6738792 Vali Loss: 0.7513743 Test Loss: 1.1301397\n",
      "Validation loss decreased (0.818508 --> 0.751374).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.6835946\n",
      "\tspeed: 0.0781s/iter; left time: 122.3234s\n",
      "Epoch: 4 cost time: 6.122465133666992\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.6327072 Vali Loss: 0.7193536 Test Loss: 1.0718168\n",
      "Validation loss decreased (0.751374 --> 0.719354).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.5914310\n",
      "\tspeed: 0.0747s/iter; left time: 103.0929s\n",
      "Epoch: 5 cost time: 6.199706315994263\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.6159828 Vali Loss: 0.7105134 Test Loss: 1.0479637\n",
      "Validation loss decreased (0.719354 --> 0.710513).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5773628\n",
      "\tspeed: 0.0808s/iter; left time: 96.6691s\n",
      "Epoch: 6 cost time: 6.332756280899048\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.6093348 Vali Loss: 0.6995338 Test Loss: 1.0383247\n",
      "Validation loss decreased (0.710513 --> 0.699534).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.6346991\n",
      "\tspeed: 0.0757s/iter; left time: 76.5577s\n",
      "Epoch: 7 cost time: 5.63312292098999\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.6046666 Vali Loss: 0.6955977 Test Loss: 1.0336225\n",
      "Validation loss decreased (0.699534 --> 0.695598).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.5918048\n",
      "\tspeed: 0.0716s/iter; left time: 59.1511s\n",
      "Epoch: 8 cost time: 5.984077215194702\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.6034021 Vali Loss: 0.6952057 Test Loss: 1.0312895\n",
      "Validation loss decreased (0.695598 --> 0.695206).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.6336913\n",
      "\tspeed: 0.0701s/iter; left time: 44.9585s\n",
      "Epoch: 9 cost time: 5.232013940811157\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.6011637 Vali Loss: 0.6962218 Test Loss: 1.0301256\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.5958022\n",
      "\tspeed: 0.0711s/iter; left time: 32.4011s\n",
      "Epoch: 10 cost time: 6.040974378585815\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.6025596 Vali Loss: 0.6939109 Test Loss: 1.0296538\n",
      "Validation loss decreased (0.695206 --> 0.693911).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.5725933\n",
      "\tspeed: 0.0733s/iter; left time: 19.8538s\n",
      "Epoch: 11 cost time: 6.482259035110474\n",
      "Epoch: 11, Steps: 185 | Train Loss: 0.6005731 Vali Loss: 0.6938241 Test Loss: 1.0293519\n",
      "Validation loss decreased (0.693911 --> 0.693824).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.5542569\n",
      "\tspeed: 0.1123s/iter; left time: 9.6549s\n",
      "Epoch: 12 cost time: 7.639321804046631\n",
      "Epoch: 12, Steps: 185 | Train Loss: 0.6023443 Vali Loss: 0.6963218 Test Loss: 1.0292218\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_Transformer_custom_ftS_sl36_ll18_pl36_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1674\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "mse:1.0217698812484741, mae:0.7676790952682495, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'Transformer',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--d_model', '16',\n",
    "        '--d_ff', '32',\n",
    "        '--des', 'Exp',\n",
    "        '--top_k', '5',\n",
    "        '--train_epochs', '12',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_rslib_training(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a27e1dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_PatchTST_custom_ftS_sl36_ll18_pl36_dm512_nh2_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 5912\n",
      "val 821\n",
      "test 1674\n",
      "\titers: 100, epoch: 1 | loss: 0.4372929\n",
      "\tspeed: 0.0284s/iter; left time: 60.2718s\n",
      "Epoch: 1 cost time: 5.059880018234253\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.6148645 Vali Loss: 0.3760077 Test Loss: 0.8768855\n",
      "Validation loss decreased (inf --> 0.376008).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6021522\n",
      "\tspeed: 0.0590s/iter; left time: 114.2012s\n",
      "Epoch: 2 cost time: 3.9839162826538086\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.4755860 Vali Loss: 0.3093416 Test Loss: 0.7799963\n",
      "Validation loss decreased (0.376008 --> 0.309342).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3138501\n",
      "\tspeed: 0.0607s/iter; left time: 106.2064s\n",
      "Epoch: 3 cost time: 4.909976005554199\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.4412630 Vali Loss: 0.2868944 Test Loss: 0.7639256\n",
      "Validation loss decreased (0.309342 --> 0.286894).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3817253\n",
      "\tspeed: 0.0600s/iter; left time: 93.9485s\n",
      "Epoch: 4 cost time: 3.760680913925171\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.4239430 Vali Loss: 0.2794696 Test Loss: 0.7635152\n",
      "Validation loss decreased (0.286894 --> 0.279470).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.4027375\n",
      "\tspeed: 0.0537s/iter; left time: 74.1527s\n",
      "Epoch: 5 cost time: 4.232661247253418\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.4225541 Vali Loss: 0.3013168 Test Loss: 0.7659703\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4435044\n",
      "\tspeed: 0.0540s/iter; left time: 64.5429s\n",
      "Epoch: 6 cost time: 4.188903570175171\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.4210071 Vali Loss: 0.2758754 Test Loss: 0.7546496\n",
      "Validation loss decreased (0.279470 --> 0.275875).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3654784\n",
      "\tspeed: 0.0545s/iter; left time: 55.1018s\n",
      "Epoch: 7 cost time: 4.117846965789795\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.4154371 Vali Loss: 0.2788349 Test Loss: 0.7622924\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3747194\n",
      "\tspeed: 0.0494s/iter; left time: 40.7698s\n",
      "Epoch: 8 cost time: 3.5400516986846924\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.4104525 Vali Loss: 0.2750406 Test Loss: 0.7596292\n",
      "Validation loss decreased (0.275875 --> 0.275041).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.3474464\n",
      "\tspeed: 0.0549s/iter; left time: 35.2137s\n",
      "Epoch: 9 cost time: 4.080622434616089\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.4155384 Vali Loss: 0.2775763 Test Loss: 0.7526140\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.4464222\n",
      "\tspeed: 0.0568s/iter; left time: 25.9045s\n",
      "Epoch: 10 cost time: 4.2066569328308105\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.4147534 Vali Loss: 0.2776866 Test Loss: 0.7568293\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.3168778\n",
      "\tspeed: 0.0545s/iter; left time: 14.7661s\n",
      "Epoch: 11 cost time: 4.239330291748047\n",
      "Epoch: 11, Steps: 185 | Train Loss: 0.4144028 Vali Loss: 0.2764305 Test Loss: 0.7597066\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_PatchTST_custom_ftS_sl36_ll18_pl36_dm512_nh2_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1674\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "mse:0.7670071721076965, mae:0.5436404943466187, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'PatchTST',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--n_heads', '2',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_rslib_training(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cad1b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_DLinear_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 5912\n",
      "val 821\n",
      "test 1674\n",
      "\titers: 100, epoch: 1 | loss: 1.2230064\n",
      "\tspeed: 0.0113s/iter; left time: 23.8689s\n",
      "Epoch: 1 cost time: 2.004391670227051\n",
      "Epoch: 1, Steps: 185 | Train Loss: 1.4279965 Vali Loss: 1.3468503 Test Loss: 1.8771271\n",
      "Validation loss decreased (inf --> 1.346850).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8658008\n",
      "\tspeed: 0.0292s/iter; left time: 56.4940s\n",
      "Epoch: 2 cost time: 1.907482624053955\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.9371984 Vali Loss: 0.9505950 Test Loss: 1.4296117\n",
      "Validation loss decreased (1.346850 --> 0.950595).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6315420\n",
      "\tspeed: 0.0293s/iter; left time: 51.3705s\n",
      "Epoch: 3 cost time: 1.980422019958496\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.7333444 Vali Loss: 0.8348511 Test Loss: 1.3167315\n",
      "Validation loss decreased (0.950595 --> 0.834851).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.6144564\n",
      "\tspeed: 0.0293s/iter; left time: 45.8149s\n",
      "Epoch: 4 cost time: 1.9009625911712646\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.6685157 Vali Loss: 0.7904772 Test Loss: 1.2767956\n",
      "Validation loss decreased (0.834851 --> 0.790477).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.7242574\n",
      "\tspeed: 0.0303s/iter; left time: 41.8930s\n",
      "Epoch: 5 cost time: 2.0200469493865967\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.6414803 Vali Loss: 0.7696495 Test Loss: 1.2599994\n",
      "Validation loss decreased (0.790477 --> 0.769650).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.6244567\n",
      "\tspeed: 0.0310s/iter; left time: 37.0340s\n",
      "Epoch: 6 cost time: 2.006028413772583\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.6291964 Vali Loss: 0.7611434 Test Loss: 1.2520934\n",
      "Validation loss decreased (0.769650 --> 0.761143).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.6915418\n",
      "\tspeed: 0.0288s/iter; left time: 29.0805s\n",
      "Epoch: 7 cost time: 1.8880789279937744\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.6230433 Vali Loss: 0.7569967 Test Loss: 1.2482080\n",
      "Validation loss decreased (0.761143 --> 0.756997).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.7154782\n",
      "\tspeed: 0.0274s/iter; left time: 22.5912s\n",
      "Epoch: 8 cost time: 1.7717454433441162\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.6200399 Vali Loss: 0.7539209 Test Loss: 1.2462554\n",
      "Validation loss decreased (0.756997 --> 0.753921).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.5582137\n",
      "\tspeed: 0.0321s/iter; left time: 20.5890s\n",
      "Epoch: 9 cost time: 2.1474437713623047\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.6187504 Vali Loss: 0.7548414 Test Loss: 1.2452503\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.5836924\n",
      "\tspeed: 0.0322s/iter; left time: 14.6815s\n",
      "Epoch: 10 cost time: 2.1481823921203613\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.6176341 Vali Loss: 0.7512303 Test Loss: 1.2447362\n",
      "Validation loss decreased (0.753921 --> 0.751230).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.6928214\n",
      "\tspeed: 0.0272s/iter; left time: 7.3577s\n",
      "Epoch: 11 cost time: 1.58805251121521\n",
      "Epoch: 11, Steps: 185 | Train Loss: 0.6174807 Vali Loss: 0.7552034 Test Loss: 1.2444741\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.6296778\n",
      "\tspeed: 0.0295s/iter; left time: 2.5355s\n",
      "Epoch: 12 cost time: 2.2967960834503174\n",
      "Epoch: 12, Steps: 185 | Train Loss: 0.6171589 Vali Loss: 0.7531592 Test Loss: 1.2443383\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 4.8828125e-08\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_DLinear_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1674\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "mse:1.2289936542510986, mae:0.8252820372581482, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'DLinear',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_rslib_training(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1502125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_Informer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 5912\n",
      "val 821\n",
      "test 1674\n",
      "\titers: 100, epoch: 1 | loss: 0.1946240\n",
      "\tspeed: 0.0780s/iter; left time: 165.5439s\n",
      "Epoch: 1 cost time: 13.941500902175903\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.3166234 Vali Loss: 0.2460666 Test Loss: 0.4484399\n",
      "Validation loss decreased (inf --> 0.246067).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2216434\n",
      "\tspeed: 0.1718s/iter; left time: 332.6259s\n",
      "Epoch: 2 cost time: 14.422443866729736\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.1861564 Vali Loss: 0.2082187 Test Loss: 0.4138702\n",
      "Validation loss decreased (0.246067 --> 0.208219).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1117789\n",
      "\tspeed: 0.1780s/iter; left time: 311.6919s\n",
      "Epoch: 3 cost time: 14.445901870727539\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.1639421 Vali Loss: 0.2018783 Test Loss: 0.4471447\n",
      "Validation loss decreased (0.208219 --> 0.201878).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1521213\n",
      "\tspeed: 0.1825s/iter; left time: 285.7792s\n",
      "Epoch: 4 cost time: 14.748233079910278\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.1522754 Vali Loss: 0.1798288 Test Loss: 0.4349265\n",
      "Validation loss decreased (0.201878 --> 0.179829).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1296762\n",
      "\tspeed: 0.1702s/iter; left time: 235.0734s\n",
      "Epoch: 5 cost time: 13.523634910583496\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.1453688 Vali Loss: 0.1850570 Test Loss: 0.4089498\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1237423\n",
      "\tspeed: 0.1640s/iter; left time: 196.1699s\n",
      "Epoch: 6 cost time: 14.050207376480103\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.1432100 Vali Loss: 0.1790783 Test Loss: 0.4079608\n",
      "Validation loss decreased (0.179829 --> 0.179078).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1304447\n",
      "\tspeed: 0.1896s/iter; left time: 191.6580s\n",
      "Epoch: 7 cost time: 15.019620656967163\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.1429519 Vali Loss: 0.1738171 Test Loss: 0.4181432\n",
      "Validation loss decreased (0.179078 --> 0.173817).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1208301\n",
      "\tspeed: 0.1789s/iter; left time: 147.7916s\n",
      "Epoch: 8 cost time: 14.648906230926514\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.1419202 Vali Loss: 0.1753847 Test Loss: 0.4100716\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1485079\n",
      "\tspeed: 0.1834s/iter; left time: 117.5280s\n",
      "Epoch: 9 cost time: 14.540398120880127\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.1404236 Vali Loss: 0.1756093 Test Loss: 0.4062583\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1482090\n",
      "\tspeed: 0.1708s/iter; left time: 77.9066s\n",
      "Epoch: 10 cost time: 13.892762184143066\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.1406274 Vali Loss: 0.1738913 Test Loss: 0.4089293\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_Informer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1674\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "mse:0.4135046899318695, mae:0.4098000228404999, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'Informer',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_rslib_training(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56f0d4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=32, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "fourier enhanced block used!\n",
      "modes=32, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=27, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      "modes_kv=18, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_FEDformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 5912\n",
      "val 821\n",
      "test 1674\n",
      "\titers: 100, epoch: 1 | loss: 0.2888545\n",
      "\tspeed: 0.4068s/iter; left time: 862.7606s\n",
      "Epoch: 1 cost time: 74.45337915420532\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.6620080 Vali Loss: 0.2941423 Test Loss: 0.6104767\n",
      "Validation loss decreased (inf --> 0.294142).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2370977\n",
      "\tspeed: 0.8318s/iter; left time: 1610.4274s\n",
      "Epoch: 2 cost time: 72.03200173377991\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.2327401 Vali Loss: 0.2333488 Test Loss: 0.5160591\n",
      "Validation loss decreased (0.294142 --> 0.233349).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2054484\n",
      "\tspeed: 0.8550s/iter; left time: 1497.0386s\n",
      "Epoch: 3 cost time: 78.74438047409058\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.2091996 Vali Loss: 0.2214839 Test Loss: 0.4935485\n",
      "Validation loss decreased (0.233349 --> 0.221484).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2163044\n",
      "\tspeed: 0.9015s/iter; left time: 1411.6904s\n",
      "Epoch: 4 cost time: 79.44915270805359\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.2027215 Vali Loss: 0.2205807 Test Loss: 0.5039825\n",
      "Validation loss decreased (0.221484 --> 0.220581).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1735936\n",
      "\tspeed: 0.8660s/iter; left time: 1195.9284s\n",
      "Epoch: 5 cost time: 79.14161157608032\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.1996668 Vali Loss: 0.2156053 Test Loss: 0.4939019\n",
      "Validation loss decreased (0.220581 --> 0.215605).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1792485\n",
      "\tspeed: 0.9118s/iter; left time: 1090.5465s\n",
      "Epoch: 6 cost time: 73.81980443000793\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.1978918 Vali Loss: 0.2161589 Test Loss: 0.4918381\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1957672\n",
      "\tspeed: 0.8035s/iter; left time: 812.3859s\n",
      "Epoch: 7 cost time: 69.69079232215881\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.1984938 Vali Loss: 0.2158409 Test Loss: 0.4925025\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.3009135\n",
      "\tspeed: 0.7922s/iter; left time: 654.3366s\n",
      "Epoch: 8 cost time: 74.87531876564026\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.1972532 Vali Loss: 0.2149480 Test Loss: 0.4927056\n",
      "Validation loss decreased (0.215605 --> 0.214948).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1770127\n",
      "\tspeed: 0.8590s/iter; left time: 550.6018s\n",
      "Epoch: 9 cost time: 75.63959288597107\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.1970715 Vali Loss: 0.2142534 Test Loss: 0.4924718\n",
      "Validation loss decreased (0.214948 --> 0.214253).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2422684\n",
      "\tspeed: 0.8753s/iter; left time: 399.1189s\n",
      "Epoch: 10 cost time: 75.49619150161743\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.1968786 Vali Loss: 0.2149339 Test Loss: 0.4918952\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1697299\n",
      "\tspeed: 0.8289s/iter; left time: 224.6387s\n",
      "Epoch: 11 cost time: 79.86773753166199\n",
      "Epoch: 11, Steps: 185 | Train Loss: 0.1966697 Vali Loss: 0.2144124 Test Loss: 0.4923160\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.2188640\n",
      "\tspeed: 0.9557s/iter; left time: 82.1874s\n",
      "Epoch: 12 cost time: 76.37270069122314\n",
      "Epoch: 12, Steps: 185 | Train Loss: 0.1970653 Vali Loss: 0.2151324 Test Loss: 0.4922946\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_FEDformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1674\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "mse:0.4920163154602051, mae:0.46418872475624084, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'FEDformer',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_rslib_training(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bfa98a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_Autoformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 5912\n",
      "val 821\n",
      "test 1674\n",
      "\titers: 100, epoch: 1 | loss: 0.9664448\n",
      "\tspeed: 0.1075s/iter; left time: 228.0724s\n",
      "Epoch: 1 cost time: 20.011178016662598\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.9055547 Vali Loss: 0.9944144 Test Loss: 1.3403921\n",
      "Validation loss decreased (inf --> 0.994414).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3069704\n",
      "\tspeed: 0.2477s/iter; left time: 479.5522s\n",
      "Epoch: 2 cost time: 20.3741512298584\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.3341758 Vali Loss: 0.8342937 Test Loss: 1.1689628\n",
      "Validation loss decreased (0.994414 --> 0.834294).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2127078\n",
      "\tspeed: 0.2525s/iter; left time: 442.0847s\n",
      "Epoch: 3 cost time: 21.25951647758484\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.2672027 Vali Loss: 0.7974808 Test Loss: 1.0854677\n",
      "Validation loss decreased (0.834294 --> 0.797481).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2717993\n",
      "\tspeed: 0.2662s/iter; left time: 416.8597s\n",
      "Epoch: 4 cost time: 21.00236749649048\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.2415081 Vali Loss: 0.8213440 Test Loss: 1.1524041\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1430255\n",
      "\tspeed: 0.2600s/iter; left time: 359.1026s\n",
      "Epoch: 5 cost time: 20.927590131759644\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.2344010 Vali Loss: 0.8490263 Test Loss: 1.1443982\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2075596\n",
      "\tspeed: 0.2453s/iter; left time: 293.3585s\n",
      "Epoch: 6 cost time: 19.693894624710083\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.2282041 Vali Loss: 0.8889154 Test Loss: 1.1646304\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_Autoformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1674\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "mse:1.0940607786178589, mae:0.7848349213600159, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'Autoformer',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_rslib_training(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1959278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_Crossformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 5912\n",
      "val 821\n",
      "test 1674\n",
      "\titers: 100, epoch: 1 | loss: 0.2439458\n",
      "\tspeed: 0.1314s/iter; left time: 278.6471s\n",
      "Epoch: 1 cost time: 23.12880825996399\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.3973501 Vali Loss: 0.2470131 Test Loss: 0.4445595\n",
      "Validation loss decreased (inf --> 0.247013).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1630995\n",
      "\tspeed: 0.2833s/iter; left time: 548.3990s\n",
      "Epoch: 2 cost time: 22.804141759872437\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.2060855 Vali Loss: 0.2432409 Test Loss: 0.5317065\n",
      "Validation loss decreased (0.247013 --> 0.243241).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1522927\n",
      "\tspeed: 0.2699s/iter; left time: 472.6744s\n",
      "Epoch: 3 cost time: 20.46946430206299\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.1825227 Vali Loss: 0.2133136 Test Loss: 0.4420210\n",
      "Validation loss decreased (0.243241 --> 0.213314).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1245394\n",
      "\tspeed: 0.2460s/iter; left time: 385.2682s\n",
      "Epoch: 4 cost time: 19.764224767684937\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.1698437 Vali Loss: 0.1906747 Test Loss: 0.4061967\n",
      "Validation loss decreased (0.213314 --> 0.190675).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1727211\n",
      "\tspeed: 0.2487s/iter; left time: 343.4099s\n",
      "Epoch: 5 cost time: 19.97537350654602\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.1649456 Vali Loss: 0.1862203 Test Loss: 0.4155714\n",
      "Validation loss decreased (0.190675 --> 0.186220).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1825671\n",
      "\tspeed: 0.2443s/iter; left time: 292.1692s\n",
      "Epoch: 6 cost time: 18.992676258087158\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.1609209 Vali Loss: 0.1898064 Test Loss: 0.4196679\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1638288\n",
      "\tspeed: 0.2213s/iter; left time: 223.6955s\n",
      "Epoch: 7 cost time: 19.015303134918213\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.1598129 Vali Loss: 0.1883834 Test Loss: 0.4154463\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2100271\n",
      "\tspeed: 0.2348s/iter; left time: 193.9111s\n",
      "Epoch: 8 cost time: 20.095128297805786\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.1595488 Vali Loss: 0.1860043 Test Loss: 0.4110539\n",
      "Validation loss decreased (0.186220 --> 0.186004).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1757320\n",
      "\tspeed: 0.2398s/iter; left time: 153.7371s\n",
      "Epoch: 9 cost time: 18.898695707321167\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.1590695 Vali Loss: 0.1873339 Test Loss: 0.4161580\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1480335\n",
      "\tspeed: 0.2279s/iter; left time: 103.9129s\n",
      "Epoch: 10 cost time: 18.786431789398193\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.1575222 Vali Loss: 0.1872625 Test Loss: 0.4142307\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1706390\n",
      "\tspeed: 0.2250s/iter; left time: 60.9792s\n",
      "Epoch: 11 cost time: 19.93035387992859\n",
      "Epoch: 11, Steps: 185 | Train Loss: 0.1585902 Vali Loss: 0.1872606 Test Loss: 0.4174308\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_Crossformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1674\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "mse:0.410085529088974, mae:0.4100993275642395, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'Crossformer',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_rslib_training(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa8301d",
   "metadata": {},
   "source": [
    "### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7762b735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu or mps\n",
      "Use CPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from modelling.forecast.tslib_util import (\n",
    "    TimeseriesTransformer,\n",
    "    TimeseriesForecaster,\n",
    ")\n",
    "\n",
    "forecaster = TimeseriesForecaster()\n",
    "forecaster.setTransformer(    \n",
    "    transformer=TimeseriesTransformer(\n",
    "        date_start=1734872400, date_scale=120, scale=True,\n",
    "        scale_mean=3.69210541, scale_std=2.06017052\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2e9ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2116888, 2.3310254, 2.523052 , 2.9497333, 2.812151 , 3.1983502,\n",
       "       3.392816 , 3.762971 , 3.9305124, 4.118539 , 4.009357 , 4.2593546,\n",
       "       4.32912  , 4.482236 , 4.4582357, 4.4998403, 4.4542484, 4.6175976,\n",
       "       4.311565 , 4.472253 , 4.666833 , 4.3761573, 4.564841 , 4.3212533,\n",
       "       4.263093 , 4.519063 , 4.6639857, 5.0408907, 4.552373 , 4.7632866,\n",
       "       5.0331054, 5.0945263, 5.279776 , 5.267578 , 5.5426326, 5.5754967],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.forecast(\n",
    "        enc_stamp = np.arange(0, 360, 10),\n",
    "        enc_data = np.array([\n",
    "            5.283333333333333,\n",
    "            5.033333333333333,\n",
    "            5.158333333333333,\n",
    "            5.15,\n",
    "            5.791666666666667,\n",
    "            6.341666666666667,\n",
    "            5.583333333333333,\n",
    "            4.858333333333333,\n",
    "            5.083333333333333,\n",
    "            4.641666666666667,\n",
    "            3.375,\n",
    "            3.15,\n",
    "            2.1333333333333333,\n",
    "            1.8833333333333333,\n",
    "            1.6,\n",
    "            1.8833333333333333,\n",
    "            1.4166666666666667,\n",
    "            1.1416666666666666,\n",
    "            0.675,\n",
    "            0.4166666666666667,\n",
    "            0.6416666666666667,\n",
    "            0.9666666666666667,\n",
    "            1.2416666666666667,\n",
    "            1.1916666666666667, \n",
    "            1.1083333333333334,\n",
    "            1.0916666666666666,\n",
    "            0.6833333333333333,\n",
    "            0.8083333333333333,\n",
    "            0.8083333333333333,\n",
    "            0.6916666666666667,\n",
    "            0.48333333333333334,\n",
    "            0.6333333333333333,\n",
    "            0.7833333333333333,\n",
    "            0.6333333333333333,\n",
    "            1.1583333333333334,\n",
    "            2.05\n",
    "        ])\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
