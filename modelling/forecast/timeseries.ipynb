{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaadd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../external/tslib')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f18c22e",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5365dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入CSV\n",
    "df = pd.read_csv('../data/request_timeseries_all.csv')\n",
    "\n",
    "# 把 timestamp 转成 date\n",
    "df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "\n",
    "# 删除原来的 timestamp\n",
    "df = df.drop(columns=['timestamp'])\n",
    "\n",
    "# 把 date 列放到最前面\n",
    "df = df[['date', 'requests']]\n",
    "\n",
    "# roll up evry 10 data points\n",
    "group_size = 10\n",
    "grouped = df.groupby(df.index // group_size)\n",
    "\n",
    "# 构建结果 DataFrame：保留起始时间，计算归一化请求数\n",
    "result = grouped.agg({\n",
    "    \"date\": \"first\",\n",
    "    \"requests\": lambda x: x.sum() / 120\n",
    "})\n",
    "\n",
    "result.to_csv('../data/request_timeseries_aggregated.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91dcbd7",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_TimesNet_custom_ftS_sl36_ll18_pl36_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 5912\n",
      "val 821\n",
      "test 1674\n",
      "\titers: 100, epoch: 1 | loss: 0.8006218\n",
      "\tspeed: 0.1288s/iter; left time: 273.2552s\n",
      "Epoch: 1 cost time: 23.77434515953064\n",
      "Epoch: 1, Steps: 185 | Train Loss: 1.0592931 Vali Loss: 0.5712931 Test Loss: 1.1151127\n",
      "Validation loss decreased (inf --> 0.571293).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3163972\n",
      "\tspeed: 0.2978s/iter; left time: 576.4578s\n",
      "Epoch: 2 cost time: 25.94798994064331\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.4102752 Vali Loss: 0.3802178 Test Loss: 0.8637551\n",
      "Validation loss decreased (0.571293 --> 0.380218).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2887527\n",
      "\tspeed: 0.3616s/iter; left time: 633.2391s\n",
      "Epoch: 3 cost time: 28.733076333999634\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.3378826 Vali Loss: 0.3086973 Test Loss: 0.7760668\n",
      "Validation loss decreased (0.380218 --> 0.308697).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2726199\n",
      "\tspeed: 0.3677s/iter; left time: 575.7461s\n",
      "Epoch: 4 cost time: 29.238857984542847\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.3157589 Vali Loss: 0.3052399 Test Loss: 0.7640244\n",
      "Validation loss decreased (0.308697 --> 0.305240).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3585177\n",
      "\tspeed: 0.3181s/iter; left time: 439.3442s\n",
      "Epoch: 5 cost time: 26.237217903137207\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.3047147 Vali Loss: 0.2965307 Test Loss: 0.7573614\n",
      "Validation loss decreased (0.305240 --> 0.296531).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3319466\n",
      "\tspeed: 0.3176s/iter; left time: 379.8619s\n",
      "Epoch: 6 cost time: 26.400001287460327\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.3018558 Vali Loss: 0.2966532 Test Loss: 0.7586580\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.2978745\n",
      "\tspeed: 0.3129s/iter; left time: 316.3717s\n",
      "Epoch: 7 cost time: 24.153799533843994\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.2975555 Vali Loss: 0.2961156 Test Loss: 0.7560703\n",
      "Validation loss decreased (0.296531 --> 0.296116).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2877584\n",
      "\tspeed: 0.3187s/iter; left time: 263.2318s\n",
      "Epoch: 8 cost time: 25.267022609710693\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.2970241 Vali Loss: 0.2944092 Test Loss: 0.7555751\n",
      "Validation loss decreased (0.296116 --> 0.294409).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.3538359\n",
      "\tspeed: 0.2992s/iter; left time: 191.8006s\n",
      "Epoch: 9 cost time: 25.252542734146118\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.2975125 Vali Loss: 0.2945339 Test Loss: 0.7565024\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1929944\n",
      "\tspeed: 0.3078s/iter; left time: 140.3529s\n",
      "Epoch: 10 cost time: 25.51483726501465\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.2961538 Vali Loss: 0.2944342 Test Loss: 0.7569045\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.2315100\n",
      "\tspeed: 0.2993s/iter; left time: 81.0968s\n",
      "Epoch: 11 cost time: 23.21797466278076\n",
      "Epoch: 11, Steps: 185 | Train Loss: 0.2997264 Vali Loss: 0.2962295 Test Loss: 0.7566645\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_TimesNet_custom_ftS_sl36_ll18_pl36_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 1674\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "test shape: (1674, 36, 1) (1674, 36, 1)\n",
      "mse:0.7633064985275269, mae:0.5624377131462097, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "# 内部用前70%作为训练集\n",
    "from forecast.tslib_util import (\n",
    "    parse_tslib_args,\n",
    "    run_rslib_training,\n",
    ")\n",
    "\n",
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'TimesNet',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--d_model', '16',\n",
    "        '--d_ff', '32',\n",
    "        '--des', 'Exp',\n",
    "        '--itr', '1',\n",
    "        '--top_k', '5',\n",
    "        '--train_epochs', '12'\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_rslib_training(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df31d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集，将数据集分为训练集和测试集，后30%作为测试集\n",
    "\n",
    "df = pd.read_csv('../data/request_timeseries_all.csv')\n",
    "train_size = int(len(df) * 0.7)\n",
    "train_data = df[:train_size]\n",
    "test_data = df[train_size:]\n",
    "train_data.to_csv('../data/request_timeseries_train.csv', index=False)\n",
    "test_data.to_csv('../data/request_timeseries_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa8301d",
   "metadata": {},
   "source": [
    "### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7762b735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu or mps\n",
      "Use CPU\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from modelling.forecast.tslib_util import (\n",
    "    TimeseriesTransformer,\n",
    "    TimeseriesForecaster,\n",
    ")\n",
    "\n",
    "forecaster = TimeseriesForecaster()\n",
    "forecaster.setTransformer(    \n",
    "    transformer=TimeseriesTransformer(\n",
    "        date_start=1734872400, date_scale=120, scale=True,\n",
    "        scale_mean=3.69210541, scale_std=2.06017052\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a2e9ba2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.2116888, 2.3310254, 2.523052 , 2.9497333, 2.812151 , 3.1983502,\n",
       "       3.392816 , 3.762971 , 3.9305124, 4.118539 , 4.009357 , 4.2593546,\n",
       "       4.32912  , 4.482236 , 4.4582357, 4.4998403, 4.4542484, 4.6175976,\n",
       "       4.311565 , 4.472253 , 4.666833 , 4.3761573, 4.564841 , 4.3212533,\n",
       "       4.263093 , 4.519063 , 4.6639857, 5.0408907, 4.552373 , 4.7632866,\n",
       "       5.0331054, 5.0945263, 5.279776 , 5.267578 , 5.5426326, 5.5754967],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecaster.forecast(\n",
    "        enc_stamp = np.arange(0, 360, 10),\n",
    "        enc_data = np.array([\n",
    "            5.283333333333333,\n",
    "            5.033333333333333,\n",
    "            5.158333333333333,\n",
    "            5.15,\n",
    "            5.791666666666667,\n",
    "            6.341666666666667,\n",
    "            5.583333333333333,\n",
    "            4.858333333333333,\n",
    "            5.083333333333333,\n",
    "            4.641666666666667,\n",
    "            3.375,\n",
    "            3.15,\n",
    "            2.1333333333333333,\n",
    "            1.8833333333333333,\n",
    "            1.6,\n",
    "            1.8833333333333333,\n",
    "            1.4166666666666667,\n",
    "            1.1416666666666666,\n",
    "            0.675,\n",
    "            0.4166666666666667,\n",
    "            0.6416666666666667,\n",
    "            0.9666666666666667,\n",
    "            1.2416666666666667,\n",
    "            1.1916666666666667, \n",
    "            1.1083333333333334,\n",
    "            1.0916666666666666,\n",
    "            0.6833333333333333,\n",
    "            0.8083333333333333,\n",
    "            0.8083333333333333,\n",
    "            0.6916666666666667,\n",
    "            0.48333333333333334,\n",
    "            0.6333333333333333,\n",
    "            0.7833333333333333,\n",
    "            0.6333333333333333,\n",
    "            1.1583333333333334,\n",
    "            2.05\n",
    "        ])\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
