{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aaadd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../external/tslib')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "import csv\n",
    "import os\n",
    "import time\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f18c22e",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5365dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读入CSV\n",
    "df = pd.read_csv('../data/request_timeseries_all.csv')\n",
    "\n",
    "# 把 timestamp 转成 date\n",
    "df['date'] = pd.to_datetime(df['timestamp'], unit='s', utc=True)\n",
    "\n",
    "# 删除原来的 timestamp\n",
    "df = df.drop(columns=['timestamp'])\n",
    "\n",
    "# 把 date 列放到最前面\n",
    "df = df[['date', 'requests']]\n",
    "\n",
    "# roll up evry 10 data points\n",
    "group_size = 10\n",
    "grouped = df.groupby(df.index // group_size)\n",
    "\n",
    "# 构建结果 DataFrame：保留起始时间，计算归一化请求数\n",
    "result = grouped.agg({\n",
    "    \"date\": \"first\",\n",
    "    \"requests\": lambda x: x.sum() / 120\n",
    "})\n",
    "\n",
    "# remove last row having less than 10 data points\n",
    "if len(df) % group_size != 0:\n",
    "    result = result[:-1]\n",
    "\n",
    "result.to_csv('../data/request_timeseries_aggregated.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df31d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分割数据集，将数据集分为训练集和测试集，后30%作为测试集\n",
    "\n",
    "df = pd.read_csv('../data/request_timeseries_all.csv')\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_data = df[:train_size]\n",
    "test_data = df[train_size:]\n",
    "train_data.to_csv('../data/request_timeseries_train.csv', index=False)\n",
    "test_data.to_csv('../data/request_timeseries_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91dcbd7",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab6e95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 内部用前80%作为训练集\n",
    "from lib.forecast.tslib_util import (\n",
    "    parse_tslib_args,\n",
    "    run_tslib_training,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51cc443f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_TimesNet_custom_ftS_sl36_ll18_pl36_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "train 5919\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "\titers: 100, epoch: 1 | loss: 1.2879006\n",
      "\tspeed: 0.1723s/iter; left time: 365.4117s\n",
      "Epoch: 1 cost time: 30.714282751083374\n",
      "Epoch: 1, Steps: 185 | Train Loss: 1.0686498 Test Loss: 0.6211281\n",
      "Validation loss decreased (inf --> 0.621128).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2518632\n",
      "\tspeed: 0.3282s/iter; left time: 635.3329s\n",
      "Epoch: 2 cost time: 26.86336374282837\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.4250385 Test Loss: 0.4046817\n",
      "Validation loss decreased (0.621128 --> 0.404682).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3063534\n",
      "\tspeed: 0.2834s/iter; left time: 496.1957s\n",
      "Epoch: 3 cost time: 24.40102791786194\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.3467557 Test Loss: 0.3545174\n",
      "Validation loss decreased (0.404682 --> 0.354517).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2653835\n",
      "\tspeed: 0.2745s/iter; left time: 429.8115s\n",
      "Epoch: 4 cost time: 24.82679796218872\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.3207552 Test Loss: 0.3608909\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3218012\n",
      "\tspeed: 0.2746s/iter; left time: 379.1690s\n",
      "Epoch: 5 cost time: 23.40908408164978\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.3104905 Test Loss: 0.3406458\n",
      "Validation loss decreased (0.354517 --> 0.340646).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3156981\n",
      "\tspeed: 0.2711s/iter; left time: 324.1816s\n",
      "Epoch: 6 cost time: 23.779331922531128\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.3069487 Test Loss: 0.3369032\n",
      "Validation loss decreased (0.340646 --> 0.336903).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3487466\n",
      "\tspeed: 0.2701s/iter; left time: 273.1079s\n",
      "Epoch: 7 cost time: 23.73058557510376\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.3024450 Test Loss: 0.3380250\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4097399\n",
      "\tspeed: 0.2661s/iter; left time: 219.7597s\n",
      "Epoch: 8 cost time: 23.1552894115448\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.3030782 Test Loss: 0.3382390\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.2469047\n",
      "\tspeed: 0.2667s/iter; left time: 170.9552s\n",
      "Epoch: 9 cost time: 23.964688777923584\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.3015293 Test Loss: 0.3383846\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_TimesNet_custom_ftS_sl36_ll18_pl36_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "mse:1.4349621534347534, mae:0.9114888310432434, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'TimesNet',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--d_model', '16',\n",
    "        '--d_ff', '32',\n",
    "        '--des', 'Exp',\n",
    "        '--itr', '1',\n",
    "        '--top_k', '5',\n",
    "        '--train_epochs', '12',\n",
    "        '--inverse',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_tslib_training(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8479c503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_Transformer_custom_ftS_sl36_ll18_pl36_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "train 5919\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "\titers: 100, epoch: 1 | loss: 0.9325890\n",
      "\tspeed: 0.0716s/iter; left time: 151.9091s\n",
      "Epoch: 1 cost time: 11.3273606300354\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.9857151 Test Loss: 1.1125985\n",
      "Validation loss decreased (inf --> 1.112599).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.9454160\n",
      "\tspeed: 0.1088s/iter; left time: 210.6893s\n",
      "Epoch: 2 cost time: 9.119707345962524\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.7827771 Test Loss: 0.9035861\n",
      "Validation loss decreased (1.112599 --> 0.903586).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.7481211\n",
      "\tspeed: 0.1049s/iter; left time: 183.7597s\n",
      "Epoch: 3 cost time: 9.591145992279053\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.6631415 Test Loss: 0.8203735\n",
      "Validation loss decreased (0.903586 --> 0.820374).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5955214\n",
      "\tspeed: 0.1202s/iter; left time: 188.2181s\n",
      "Epoch: 4 cost time: 10.21713399887085\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.6253034 Test Loss: 0.7851454\n",
      "Validation loss decreased (0.820374 --> 0.785145).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6614004\n",
      "\tspeed: 0.1022s/iter; left time: 141.1426s\n",
      "Epoch: 5 cost time: 8.766276597976685\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.6098948 Test Loss: 0.7708071\n",
      "Validation loss decreased (0.785145 --> 0.770807).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5671673\n",
      "\tspeed: 0.1054s/iter; left time: 126.0708s\n",
      "Epoch: 6 cost time: 9.164780378341675\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.6026331 Test Loss: 0.7628189\n",
      "Validation loss decreased (0.770807 --> 0.762819).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.6208875\n",
      "\tspeed: 0.1088s/iter; left time: 109.9703s\n",
      "Epoch: 7 cost time: 9.32715392112732\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.5983649 Test Loss: 0.7587758\n",
      "Validation loss decreased (0.762819 --> 0.758776).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.5583915\n",
      "\tspeed: 0.1057s/iter; left time: 87.2867s\n",
      "Epoch: 8 cost time: 9.187463760375977\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.5965762 Test Loss: 0.7569871\n",
      "Validation loss decreased (0.758776 --> 0.756987).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.5965860\n",
      "\tspeed: 0.1047s/iter; left time: 67.1189s\n",
      "Epoch: 9 cost time: 9.143500328063965\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.5960857 Test Loss: 0.7560628\n",
      "Validation loss decreased (0.756987 --> 0.756063).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.5049984\n",
      "\tspeed: 0.1024s/iter; left time: 46.7008s\n",
      "Epoch: 10 cost time: 9.207483530044556\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.5959982 Test Loss: 0.7556387\n",
      "Validation loss decreased (0.756063 --> 0.755639).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.5266622\n",
      "\tspeed: 0.1048s/iter; left time: 28.4004s\n",
      "Epoch: 11 cost time: 9.266889810562134\n",
      "Epoch: 11, Steps: 185 | Train Loss: 0.5961722 Test Loss: 0.7554218\n",
      "Validation loss decreased (0.755639 --> 0.755422).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.6586166\n",
      "\tspeed: 0.1070s/iter; left time: 9.2028s\n",
      "Epoch: 12 cost time: 9.338663816452026\n",
      "Epoch: 12, Steps: 185 | Train Loss: 0.5955449 Test Loss: 0.7553122\n",
      "Validation loss decreased (0.755422 --> 0.755312).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_Transformer_custom_ftS_sl36_ll18_pl36_dm16_nh8_el2_dl1_df32_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "mse:3.204148292541504, mae:1.4443269968032837, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'Transformer',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--d_model', '16',\n",
    "        '--d_ff', '32',\n",
    "        '--des', 'Exp',\n",
    "        '--top_k', '5',\n",
    "        '--train_epochs', '12',\n",
    "        '--inverse',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_tslib_training(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a27e1dac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_PatchTST_custom_ftS_sl36_ll18_pl36_dm512_nh2_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "train 5919\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "\titers: 100, epoch: 1 | loss: 0.4385456\n",
      "\tspeed: 0.0382s/iter; left time: 80.9713s\n",
      "Epoch: 1 cost time: 6.0795183181762695\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.6120434 Test Loss: 0.3671558\n",
      "Validation loss decreased (inf --> 0.367156).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.4639916\n",
      "\tspeed: 0.0902s/iter; left time: 174.6906s\n",
      "Epoch: 2 cost time: 8.688975095748901\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.4741322 Test Loss: 0.3858618\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.5068045\n",
      "\tspeed: 0.0780s/iter; left time: 136.6064s\n",
      "Epoch: 3 cost time: 6.551538705825806\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.4399246 Test Loss: 0.3762212\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.5057787\n",
      "\tspeed: 0.0735s/iter; left time: 115.0781s\n",
      "Epoch: 4 cost time: 5.547212600708008\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.4319980 Test Loss: 0.3534613\n",
      "Validation loss decreased (0.367156 --> 0.353461).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3887818\n",
      "\tspeed: 0.0653s/iter; left time: 90.1821s\n",
      "Epoch: 5 cost time: 5.277015447616577\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.4194579 Test Loss: 0.3270754\n",
      "Validation loss decreased (0.353461 --> 0.327075).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.4301948\n",
      "\tspeed: 0.0672s/iter; left time: 80.3923s\n",
      "Epoch: 6 cost time: 5.267809152603149\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.4153818 Test Loss: 0.3377273\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3775390\n",
      "\tspeed: 0.0607s/iter; left time: 61.3508s\n",
      "Epoch: 7 cost time: 5.52863335609436\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.4119364 Test Loss: 0.3354435\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.4968834\n",
      "\tspeed: 0.0667s/iter; left time: 55.1294s\n",
      "Epoch: 8 cost time: 5.158586025238037\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.4095773 Test Loss: 0.3335594\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_PatchTST_custom_ftS_sl36_ll18_pl36_dm512_nh2_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "mse:1.3934029340744019, mae:0.8758319616317749, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'PatchTST',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--n_heads', '2',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--inverse',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_tslib_training(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cad1b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_DLinear_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "train 5919\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "\titers: 100, epoch: 1 | loss: 1.2265337\n",
      "\tspeed: 0.0197s/iter; left time: 41.7053s\n",
      "Epoch: 1 cost time: 3.339123249053955\n",
      "Epoch: 1, Steps: 185 | Train Loss: 1.4302526 Test Loss: 1.5233018\n",
      "Validation loss decreased (inf --> 1.523302).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8414343\n",
      "\tspeed: 0.0360s/iter; left time: 69.7744s\n",
      "Epoch: 2 cost time: 2.803664445877075\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.9364815 Test Loss: 1.0602875\n",
      "Validation loss decreased (1.523302 --> 1.060287).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6594452\n",
      "\tspeed: 0.0410s/iter; left time: 71.8173s\n",
      "Epoch: 3 cost time: 3.2661097049713135\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.7327479 Test Loss: 0.9274227\n",
      "Validation loss decreased (1.060287 --> 0.927423).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.7541259\n",
      "\tspeed: 0.0429s/iter; left time: 67.2071s\n",
      "Epoch: 4 cost time: 3.2005739212036133\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.6675000 Test Loss: 0.8767253\n",
      "Validation loss decreased (0.927423 --> 0.876725).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.6471894\n",
      "\tspeed: 0.0415s/iter; left time: 57.2858s\n",
      "Epoch: 5 cost time: 3.147698163986206\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.6409735 Test Loss: 0.8539100\n",
      "Validation loss decreased (0.876725 --> 0.853910).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.5722103\n",
      "\tspeed: 0.0345s/iter; left time: 41.3151s\n",
      "Epoch: 6 cost time: 2.5767786502838135\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.6287004 Test Loss: 0.8428007\n",
      "Validation loss decreased (0.853910 --> 0.842801).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.5799836\n",
      "\tspeed: 0.0316s/iter; left time: 31.9782s\n",
      "Epoch: 7 cost time: 2.4092719554901123\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.6226181 Test Loss: 0.8371834\n",
      "Validation loss decreased (0.842801 --> 0.837183).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.6457995\n",
      "\tspeed: 0.0331s/iter; left time: 27.3718s\n",
      "Epoch: 8 cost time: 2.6903324127197266\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.6195882 Test Loss: 0.8343229\n",
      "Validation loss decreased (0.837183 --> 0.834323).  Saving model ...\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.5717209\n",
      "\tspeed: 0.0368s/iter; left time: 23.5662s\n",
      "Epoch: 9 cost time: 2.818978786468506\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.6179773 Test Loss: 0.8328359\n",
      "Validation loss decreased (0.834323 --> 0.832836).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.5223320\n",
      "\tspeed: 0.0362s/iter; left time: 16.5223s\n",
      "Epoch: 10 cost time: 2.7516956329345703\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.6171751 Test Loss: 0.8320715\n",
      "Validation loss decreased (0.832836 --> 0.832071).  Saving model ...\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.6187772\n",
      "\tspeed: 0.0359s/iter; left time: 9.7331s\n",
      "Epoch: 11 cost time: 2.8119492530822754\n",
      "Epoch: 11, Steps: 185 | Train Loss: 0.6167153 Test Loss: 0.8316784\n",
      "Validation loss decreased (0.832071 --> 0.831678).  Saving model ...\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.5973061\n",
      "\tspeed: 0.0352s/iter; left time: 3.0287s\n",
      "Epoch: 12 cost time: 2.8084728717803955\n",
      "Epoch: 12, Steps: 185 | Train Loss: 0.6165281 Test Loss: 0.8314743\n",
      "Validation loss decreased (0.831678 --> 0.831474).  Saving model ...\n",
      "Updating learning rate to 4.8828125e-08\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_DLinear_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "mse:3.5310139656066895, mae:1.5049372911453247, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'DLinear',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--inverse',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_tslib_training(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1502125f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_Informer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "train 5919\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "\titers: 100, epoch: 1 | loss: 0.2685606\n",
      "\tspeed: 0.0908s/iter; left time: 192.6410s\n",
      "Epoch: 1 cost time: 16.81754159927368\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.3120998 Test Loss: 0.2506303\n",
      "Validation loss decreased (inf --> 0.250630).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1616997\n",
      "\tspeed: 0.1953s/iter; left time: 378.0249s\n",
      "Epoch: 2 cost time: 16.36061120033264\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.1846308 Test Loss: 0.2379891\n",
      "Validation loss decreased (0.250630 --> 0.237989).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1690879\n",
      "\tspeed: 0.1878s/iter; left time: 328.8788s\n",
      "Epoch: 3 cost time: 16.18420720100403\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.1628206 Test Loss: 0.2003696\n",
      "Validation loss decreased (0.237989 --> 0.200370).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1072278\n",
      "\tspeed: 0.1876s/iter; left time: 293.7291s\n",
      "Epoch: 4 cost time: 16.077341079711914\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.1517681 Test Loss: 0.1887563\n",
      "Validation loss decreased (0.200370 --> 0.188756).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1661569\n",
      "\tspeed: 0.1922s/iter; left time: 265.4940s\n",
      "Epoch: 5 cost time: 16.47799777984619\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.1456107 Test Loss: 0.1860913\n",
      "Validation loss decreased (0.188756 --> 0.186091).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1268619\n",
      "\tspeed: 0.1933s/iter; left time: 231.1770s\n",
      "Epoch: 6 cost time: 16.623669624328613\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.1435912 Test Loss: 0.1802971\n",
      "Validation loss decreased (0.186091 --> 0.180297).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1420904\n",
      "\tspeed: 0.1923s/iter; left time: 194.4022s\n",
      "Epoch: 7 cost time: 16.91207981109619\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.1422874 Test Loss: 0.1828402\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1181061\n",
      "\tspeed: 0.1852s/iter; left time: 152.9393s\n",
      "Epoch: 8 cost time: 16.063080310821533\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.1412325 Test Loss: 0.1811056\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1391506\n",
      "\tspeed: 0.1826s/iter; left time: 117.0335s\n",
      "Epoch: 9 cost time: 16.46531319618225\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.1406999 Test Loss: 0.1790558\n",
      "Validation loss decreased (0.180297 --> 0.179056).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1967306\n",
      "\tspeed: 0.1879s/iter; left time: 85.7001s\n",
      "Epoch: 10 cost time: 15.97837495803833\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.1401864 Test Loss: 0.1834188\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1339579\n",
      "\tspeed: 0.1834s/iter; left time: 49.6922s\n",
      "Epoch: 11 cost time: 16.70339298248291\n",
      "Epoch: 11, Steps: 185 | Train Loss: 0.1398468 Test Loss: 0.1808121\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1108466\n",
      "\tspeed: 0.1832s/iter; left time: 15.7573s\n",
      "Epoch: 12 cost time: 16.656650066375732\n",
      "Epoch: 12, Steps: 185 | Train Loss: 0.1400519 Test Loss: 0.1798610\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_Informer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "mse:0.7580368518829346, mae:0.6546733975410461, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'Informer',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--inverse',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_tslib_training(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f0d4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      "fourier enhanced block used!\n",
      "modes=32, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "fourier enhanced block used!\n",
      "modes=32, index=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      " fourier enhanced cross attention used!\n",
      "modes_q=27, index_q=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]\n",
      "modes_kv=18, index_kv=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_FEDformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "train 5919\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "\titers: 100, epoch: 1 | loss: 0.3294568\n",
      "\tspeed: 0.5261s/iter; left time: 1115.7587s\n",
      "Epoch: 1 cost time: 99.0444586277008\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.6579430 Test Loss: 0.3392315\n",
      "Validation loss decreased (inf --> 0.339231).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.1994325\n",
      "\tspeed: 1.1032s/iter; left time: 2135.7843s\n",
      "Epoch: 2 cost time: 104.52512621879578\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.2339370 Test Loss: 0.2777430\n",
      "Validation loss decreased (0.339231 --> 0.277743).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2039351\n",
      "\tspeed: 1.1341s/iter; left time: 1985.8293s\n",
      "Epoch: 3 cost time: 104.73119878768921\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.2096723 Test Loss: 0.2533947\n",
      "Validation loss decreased (0.277743 --> 0.253395).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1992936\n",
      "\tspeed: 1.1084s/iter; left time: 1735.7164s\n",
      "Epoch: 4 cost time: 99.35229015350342\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.2032075 Test Loss: 0.2467969\n",
      "Validation loss decreased (0.253395 --> 0.246797).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2107626\n",
      "\tspeed: 1.0796s/iter; left time: 1490.9667s\n",
      "Epoch: 5 cost time: 100.15510725975037\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.1998919 Test Loss: 0.2378395\n",
      "Validation loss decreased (0.246797 --> 0.237840).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1580371\n",
      "\tspeed: 1.0905s/iter; left time: 1304.2686s\n",
      "Epoch: 6 cost time: 100.1958909034729\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.1986313 Test Loss: 0.2434166\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1901312\n",
      "\tspeed: 1.0708s/iter; left time: 1082.5505s\n",
      "Epoch: 7 cost time: 99.99403834342957\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.1978505 Test Loss: 0.2395536\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2307034\n",
      "\tspeed: 1.0656s/iter; left time: 880.1490s\n",
      "Epoch: 8 cost time: 98.39423632621765\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.1972239 Test Loss: 0.2406036\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_FEDformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "mse:1.0111392736434937, mae:0.7808594703674316, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'FEDformer',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--inverse',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_tslib_training(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bfa98a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_Autoformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "train 5919\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "\titers: 100, epoch: 1 | loss: 0.7080758\n",
      "\tspeed: 0.1259s/iter; left time: 267.0674s\n",
      "Epoch: 1 cost time: 22.986199617385864\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.9188149 Test Loss: 0.7926010\n",
      "Validation loss decreased (inf --> 0.792601).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2466152\n",
      "\tspeed: 0.2718s/iter; left time: 526.2251s\n",
      "Epoch: 2 cost time: 23.935683250427246\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.3220102 Test Loss: 0.7799638\n",
      "Validation loss decreased (0.792601 --> 0.779964).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3066706\n",
      "\tspeed: 0.2680s/iter; left time: 469.1909s\n",
      "Epoch: 3 cost time: 22.55714440345764\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.2674883 Test Loss: 0.6214460\n",
      "Validation loss decreased (0.779964 --> 0.621446).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2706830\n",
      "\tspeed: 0.2668s/iter; left time: 417.7798s\n",
      "Epoch: 4 cost time: 23.06917381286621\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.2501863 Test Loss: 0.7007070\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2310303\n",
      "\tspeed: 0.2630s/iter; left time: 363.1698s\n",
      "Epoch: 5 cost time: 23.42717409133911\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.2354781 Test Loss: 0.6734343\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2016264\n",
      "\tspeed: 0.2647s/iter; left time: 316.5952s\n",
      "Epoch: 6 cost time: 23.983108282089233\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.2320104 Test Loss: 0.6913737\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_Autoformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "mse:2.645641565322876, mae:1.2820838689804077, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'Autoformer',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--inverse',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_tslib_training(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1959278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : long_term_forecast_ts_36_36_Crossformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "train 5919\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "\titers: 100, epoch: 1 | loss: 0.2533940\n",
      "\tspeed: 0.1433s/iter; left time: 303.9424s\n",
      "Epoch: 1 cost time: 25.802560567855835\n",
      "Epoch: 1, Steps: 185 | Train Loss: 0.4166359 Test Loss: 0.2348586\n",
      "Validation loss decreased (inf --> 0.234859).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2841390\n",
      "\tspeed: 0.2976s/iter; left time: 576.0925s\n",
      "Epoch: 2 cost time: 25.237106561660767\n",
      "Epoch: 2, Steps: 185 | Train Loss: 0.2058320 Test Loss: 0.2497153\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.1734549\n",
      "\tspeed: 0.2767s/iter; left time: 484.5783s\n",
      "Epoch: 3 cost time: 25.203734874725342\n",
      "Epoch: 3, Steps: 185 | Train Loss: 0.1815719 Test Loss: 0.2106991\n",
      "Validation loss decreased (0.234859 --> 0.210699).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.1790042\n",
      "\tspeed: 0.3091s/iter; left time: 484.0115s\n",
      "Epoch: 4 cost time: 25.574135541915894\n",
      "Epoch: 4, Steps: 185 | Train Loss: 0.1693970 Test Loss: 0.2007298\n",
      "Validation loss decreased (0.210699 --> 0.200730).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.1671740\n",
      "\tspeed: 0.2987s/iter; left time: 412.4982s\n",
      "Epoch: 5 cost time: 25.31562852859497\n",
      "Epoch: 5, Steps: 185 | Train Loss: 0.1649828 Test Loss: 0.1927470\n",
      "Validation loss decreased (0.200730 --> 0.192747).  Saving model ...\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.1372564\n",
      "\tspeed: 0.3019s/iter; left time: 361.0190s\n",
      "Epoch: 6 cost time: 25.57721185684204\n",
      "Epoch: 6, Steps: 185 | Train Loss: 0.1613887 Test Loss: 0.1918318\n",
      "Validation loss decreased (0.192747 --> 0.191832).  Saving model ...\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.1678960\n",
      "\tspeed: 0.3077s/iter; left time: 311.0659s\n",
      "Epoch: 7 cost time: 25.747281074523926\n",
      "Epoch: 7, Steps: 185 | Train Loss: 0.1591445 Test Loss: 0.1961941\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.1384316\n",
      "\tspeed: 0.2778s/iter; left time: 229.4974s\n",
      "Epoch: 8 cost time: 25.16879367828369\n",
      "Epoch: 8, Steps: 185 | Train Loss: 0.1589373 Test Loss: 0.1936660\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 7.8125e-07\n",
      "\titers: 100, epoch: 9 | loss: 0.1590142\n",
      "\tspeed: 0.2793s/iter; left time: 179.0299s\n",
      "Epoch: 9 cost time: 24.86583375930786\n",
      "Epoch: 9, Steps: 185 | Train Loss: 0.1582253 Test Loss: 0.1911671\n",
      "Validation loss decreased (0.191832 --> 0.191167).  Saving model ...\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.1409584\n",
      "\tspeed: 0.2990s/iter; left time: 136.3622s\n",
      "Epoch: 10 cost time: 25.63355588912964\n",
      "Epoch: 10, Steps: 185 | Train Loss: 0.1582003 Test Loss: 0.1913932\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 1.953125e-07\n",
      "\titers: 100, epoch: 11 | loss: 0.1671912\n",
      "\tspeed: 0.2755s/iter; left time: 74.6576s\n",
      "Epoch: 11 cost time: 24.300230264663696\n",
      "Epoch: 11, Steps: 185 | Train Loss: 0.1579147 Test Loss: 0.1919976\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 9.765625e-08\n",
      "\titers: 100, epoch: 12 | loss: 0.1671857\n",
      "\tspeed: 0.2691s/iter; left time: 23.1417s\n",
      "Epoch: 12 cost time: 24.718563556671143\n",
      "Epoch: 12, Steps: 185 | Train Loss: 0.1576005 Test Loss: 0.1922501\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : long_term_forecast_ts_36_36_Crossformer_custom_ftS_sl36_ll18_pl36_dm512_nh8_el2_dl1_df2048_expand2_dc4_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "Scaler mean: [3.69341263]\n",
      "Scaler std: [2.05966675]\n",
      "test 1462\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "test shape: (1462, 36, 1) (1462, 36, 1)\n",
      "mse:0.8130908608436584, mae:0.6726071834564209, dtw:Not calculated\n"
     ]
    }
   ],
   "source": [
    "args = parse_tslib_args(\n",
    "    [\n",
    "        '--root_path', '../data/',\n",
    "        '--data_path', 'request_timeseries_aggregated.csv',\n",
    "        '--model_id', 'ts_36_36',\n",
    "        '--model', 'Crossformer',\n",
    "        '--data', 'custom',\n",
    "        '--features', 'S',\n",
    "        '--target', 'requests',\n",
    "        '--freq', 'h',\n",
    "        '--seq_len', '36',\n",
    "        '--label_len', '18',\n",
    "        '--pred_len', '36',\n",
    "        '--e_layers', '2',\n",
    "        '--d_layers', '1',\n",
    "        '--factor', '3',\n",
    "        '--enc_in', '1',\n",
    "        '--dec_in', '1',\n",
    "        '--c_out', '1',\n",
    "        '--des', 'Exp',\n",
    "        '--train_epochs', '12',\n",
    "        '--inverse',\n",
    "        '--use_gpu', 'True'\n",
    "    ]\n",
    ")\n",
    "\n",
    "run_tslib_training(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa8301d",
   "metadata": {},
   "source": [
    "### Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7762b735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu or mps\n",
      "Use CPU\n"
     ]
    }
   ],
   "source": [
    "import lib.forecast.tslib_util as tslib_util\n",
    "\n",
    "\n",
    "forecaster = tslib_util.TimeseriesForecaster()\n",
    "forecaster.setTransformer(    \n",
    "    transformer=tslib_util.TimeseriesTransformer(\n",
    "        date_start=1742028000, date_scale=120, scale=True,\n",
    "        scale_mean=3.69341263, scale_std=2.05966675\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a2e9ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = forecaster.forecast(\n",
    "        enc_stamp = np.arange(0, 360, 10),\n",
    "        enc_data = np.array([\n",
    "            5.5,\n",
    "            4.4,\n",
    "            4.316666666666666,\n",
    "            4.491666666666666,\n",
    "            5.35,\n",
    "            5.433333333333334,\n",
    "            4.908333333333333,\n",
    "            4.375,\n",
    "            4.091666666666667,\n",
    "            3.525,\n",
    "            4.966666666666667,\n",
    "            5.025,\n",
    "            4.691666666666666,\n",
    "            4.733333333333333,\n",
    "            4.75,\n",
    "            4.95,\n",
    "            5.358333333333333,\n",
    "            6.191666666666666,\n",
    "            5.7,\n",
    "            6.15,\n",
    "            6.508333333333334,\n",
    "            5.733333333333333,\n",
    "            6.266666666666667,\n",
    "            4.925,\n",
    "            4.316666666666666,\n",
    "            5.041666666666667,\n",
    "            5.791666666666667,\n",
    "            5.7,\n",
    "            6.491666666666666,\n",
    "            6.225,\n",
    "            4.883333333333334,\n",
    "            4.891666666666667,\n",
    "            4.066666666666666,\n",
    "            3.5833333333333335,\n",
    "            3.533333333333333,\n",
    "            3.5,\n",
    "        ]),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "127e1c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2641409895714611"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.mean_ = np.array([3.69341263])\n",
    "scaler.scale_ = np.array([2.05966675])\n",
    "\n",
    "\n",
    "# 真实值\n",
    "true_values = np.array([\n",
    "    2.233333333333333,\n",
    "    1.941666666666666,\n",
    "    2.208333333333333,\n",
    "    2.083333333333333,\n",
    "    2.008333333333333,\n",
    "    1.891666666666666,\n",
    "    1.383333333333333,\n",
    "    1.158333333333333,\n",
    "    1.175,\n",
    "    0.958333333333333,\n",
    "    0.816666666666666,\n",
    "    1.033333333333333,\n",
    "    0.758333333333333,\n",
    "    0.841666666666666,\n",
    "    0.808333333333333,\n",
    "    0.691666666666666,\n",
    "    0.875,\n",
    "    0.866666666666666,\n",
    "    0.858333333333333,\n",
    "    1.125,\n",
    "    1.366666666666666,\n",
    "    1.375,\n",
    "    1.833333333333333,\n",
    "    2.241666666666666,\n",
    "    2.658333333333333,\n",
    "    3.441666666666667,\n",
    "    4.191666666666666,\n",
    "    3.85,\n",
    "    4.191666666666666,\n",
    "    3.225,\n",
    "    3.15,\n",
    "    2.825,\n",
    "    4.175,\n",
    "    4.783333333333333,\n",
    "    4.925,\n",
    "    4.625,\n",
    "])\n",
    "\n",
    "# 预测值\n",
    "predicted_values = result\n",
    "\n",
    "# 计算 MSE\n",
    "mse = mean_squared_error(true_values, predicted_values)\n",
    "mse\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
